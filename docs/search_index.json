[["index.html", "Data nalaysis for Newquay University Centre Chapter 1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " Data nalaysis for Newquay University Centre Michael Hunt 2024-05-29 Chapter 1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["plot-your-data.html", "Chapter 2 Plot your data 2.1 Load packages 2.2 Get the template script 2.3 Load the Palmer penguin data 2.4 Summary stats on all the numeric columns 2.5 Remove the rows with NAs 2.6 How many observations are there for each species? 2.7 Mean value for each numerical variable, for each species 2.8 Scatter plots 2.9 Repeat for bill length and flipper length 2.10 Add yet more informtion to the plot 2.11 Distribution of penguin flipper lengths 2.12 Bar chart with error bar", " Chapter 2 Plot your data In this exercise we are going to produce and improve a variety of useful and widely used plots using the package ggplot which is part of the larger tidyverse package. You will see that the code to do each plot is very similar, whatever the type of plot, and that plots can be built up from very basic forms to become really attractive, informative versions with very little additional effort. You need to read the examples in this worksheet and then fill in the missing code or alter what is provided already in the empty code chunks of the accompanying template script. Instructions for getting that are given below. As you complete each code chunk, try it out by pressing the green arrow at the top right of the chunk. Sometimes you might want to try out an individual line. You can do that by placing the cursor anywhere in the line and pressing Controll-Entr (windows) or Command-Enter (Mac) Remember that the template is a markdown document, so you can add extra text between the code chunks to explain to yourself what is going on. You can format this test, if you wish, according to the very basic markdown rules for doing this. See Help/Markdown Quick Reference. This formatting is only useful if you ‘knit’ the script, by pressing the knit button at the top of the script pane. Try this! I suggest you knit to html. This is how the worksheet you are working from was produced. 2.1 Load packages # install.packages(&quot;name of package&quot;) # run this line once, if you need to, for any of the packages that need to be installed library(tidyverse) library(here) library(palmerpenguins) library(devtools) 2.2 Get the template script This next chunk will download the template file that you need to fill in as you work through this worksheet, and put it in the scripts subfolder within your project folder. For it to work, you need to be ‘working in your Project’ - in which case the name of the project will appear in the top right of the main RStudio window, and if you have a subfolder within the project folder called ‘scripts’. If any of that is not true, it needs to be sorted now! file_url &lt;- &quot;https://raw.githubusercontent.com/mbh038/r-workshop/gh-pages/scripts/ggplot_examples_template.Rmd&quot; file_dest &lt;- here(&quot;scripts&quot;,&quot;my_ggplot_examples.rmd&quot;) download.file(file_url,file_dest) 2.3 Load the Palmer penguin data For this exercise we use the Palmer penguins data set which comes with the package palmerpenguins The palmerpenguin package contains two built-in data sets. One is called penguins: Here we load the data into this R session (you will now see it in the Environment pane) and we inspect it using the function glimpse(). data(penguins) glimpse(penguins) ## Rows: 344 ## Columns: 8 ## $ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … ## $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… ## $ body_mass_g &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … ## $ sex &lt;fct&gt; male, female, female, NA, female, male, female, male… ## $ year &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… How many rows are there and how many columns? For more detailed meta-information on the data we just type the name of the data set with a question mark before it: ?penguins 2.4 Summary stats on all the numeric columns This is in general useful to get, at least for the columns that contain numerical data, since it shows which columns contains NAs,which is R-speak for missing data. They are how R represents what would be empty cells in an Excel spreadsheet. summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 We see that there are some rows with NAs in for a few of the columns. We need to be aware of this when doing calculations wih the data, such as taking means. Here, we will remove those rows: 2.5 Remove the rows with NAs penguins &lt;- penguins |&gt; drop_na() 2.6 How many observations are there for each species? Note the use of the pipe operator |&gt;, here and throughout. Think of it as meaning and then. It feeds the output of one line into the function of the next line, where it is used as that function’s first argument. penguins |&gt; count(species) ## # A tibble: 3 × 2 ## species n ## &lt;fct&gt; &lt;int&gt; ## 1 Adelie 146 ## 2 Chinstrap 68 ## 3 Gentoo 119 2.7 Mean value for each numerical variable, for each species Here is an example of the use of the group_by() then summarise() combination, whereby data is first grouped, here by species, then summary statistics (of your choice) are calculated for each group. In this example the data are grouped by species, then the mean value of all the columns that contain numerical data are calculated, not just an overall value for the whole column, but for each species penguins |&gt; group_by(species) |&gt; summarize(across(where(is.numeric), mean, na.rm = TRUE)) |&gt; ungroup() # good practice to include this at the end. ## # A tibble: 3 × 6 ## species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 18.3 190. 3706. 2008. ## 2 Chinstrap 48.8 18.4 196. 3733. 2008. ## 3 Gentoo 47.6 15.0 217. 5092. 2008. 2.8 Scatter plots Is flipper length correlated with body mass? We could a do correlation test to find this out, but let us first plot the data. We will show here how an elegant plot can be built up, starting from a very basic one, so that you see what each line of code for the finished version actually does. In the chunks below, run each one in turn to see the effect of each successive change that you make. First we feed the penguin data to the function ggplot(), and use its aes() argument to tell it which variables are to be ‘mapped’ to which aesthetic (which means, roughly speaking, ‘visible’) features of the plot, such as the x-axis, the y-axis, point and line colours, fill colours, symbol types and size etc: penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g)) This produces the first layer of the eventual finished plot, an empty plot, ready to display data. Before it can do this, ggplot() needs to be told how you want to do so - what type of plot do you want? For that, we add a geom.....() line, to specify the type of plot. There are lots of geom types, but for a scatter plot we use geom_point(): penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g)) + geom_point() This gives us a recognisable scatter plot, but it is deficient in a number of ways. For starters, we know that there are three species of penguin. It would be better if each were plotted using symbols of a different colour, shape or size. We can do this by adding in an extra argument to the aesthetic in the first line. Here we include colour = species. penguins |&gt; ggplot(aes(x = flipper_length_mm,y = body_mass_g, colour = species)) + geom_point() Can you guess what you should have do if you wanted not the symbol colour, but its shape or size to depend on species? Clue: change one word! Now we add labels, titles and so on, using the line labs(...). Note how we can actually write the arguments of this over several lines on the page, for clarity. penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) + geom_point() + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Body mass (g)&quot;, colour= &quot;Species&quot;, # this changes the title of the legend. title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins&quot;, caption = &quot;Alternative place to put the information in the subtitle&quot;) It can be useful to include some combination of titles, subtitles and captions if the figure is to be used as part of a presentation or poster, but if it is to go in a report, you would normally only include a caption, and let the word-processing software do it, and if just for exploratory analysis, not even that. I normally do include axis labels, however. Now we use a theme to alter the overall look of the figure. There are several built-in themes you can choose from, and others from packages that you can use. I usually use theme_cowplot() from the cowplot package. Try typing ?theme at the command prompt in the console window to see what is available. Here, we use the built-in theme_bw(): penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) + geom_point() + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Body mass (g)&quot;, colour= &quot;Species&quot;, title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins&quot;) + theme_bw() Now we reposition the legend. We don’t have to, but we might not like the default position of the legend. If not, we can move or even remove it using another theme() line. The position argument of this can be “none” if you want to remove it, top”, “bottom”, “left”, “right” or a numerical vector in relative coordinates, where c(0,0) means bottom left within the plot, and c(1,1) means top-right. This is what we use here. Play around with different values. penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) + geom_point() + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Body mass (g)&quot;, colour= &quot;Species&quot;, title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins&quot;) + theme_bw() + theme(legend.position = c(0.2,0.8)) # try &quot;top&quot;, &quot;left&quot; etc Nicer colours. If you don’t like the default colours offered by R, there are several other palettes available, for example the Brewer palettes, borrowed from the world of maps. See https://colorbrewer2.org ,and for a list of the available palettes, type &gt;?scale_colour_brewer into the console pane then look at the help that appears in the Help pane (bottom right), and scroll down to the palettes section. Note that we dont have to alter the colours. But doing so can make your plots not only look nicer, but serve some other purpose, such as to be colour-blind friendly, or have colours that are appropriate for the variables being plotted (eg red points for red things, blue points for blue things). For an assignment or dissertation report, it is a good idea to pick a palette that you like and that works, and stick with it, so that all your plots have the same general look. Here we choose the qualitative palette \"Set2\" and use it by by adding the line scale_colour_brewer(palette=\"Set2\"). Try a few other palettes. penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) + geom_point() + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Body mass (g)&quot;, colour= &quot;Species&quot;, title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins&quot;) + scale_colour_brewer(palette=&quot;Set2&quot;) + # try other palettes eg &quot;Set3&quot; theme_bw() + theme(legend.position = c(0.2,0.8)) # try &quot;top&quot;, &quot;left&quot; etc If we like, we can add best fit lines to each subset of the data, using geom_smooth(). To produce straight line fits, geom_smooth() needs to be told to use a linear model, using the method = \"lm\" argument. By default, you will get lines with a grey 95% confidence band around them. This can be useful, but if you don’t want it, add the argument se = FALSE, as we have done below. We have also altered the linewidth. penguins |&gt; ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) + geom_point() + geom_smooth(method=&quot;lm&quot;, linewidth=0.5,se=FALSE) + # try leaving out the se argument labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Body mass (g)&quot;, colour= &quot;Species&quot;, title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins&quot;) + scale_colour_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = c(0.2,0.8)) # also try legend.position = &quot;top&quot;, &quot;left&quot; etc 2.9 Repeat for bill length and flipper length Modify the code of the previous plot so that you now plot bill length vs flipper length. Adjust any labels and titles as necessary. This time, put the legend in the bottom right of the plot. penguins |&gt; ggplot(aes(x=flipper_length_mm,y=bill_length_mm,colour=species)) + geom_point() + geom_smooth(method=&quot;lm&quot;, linewidth=0.5,se=FALSE) + # try leaving out the se argument labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Bill length (mm)&quot;, colour= &quot;Species&quot;, title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and bill length for Adelie, Chinstrap, and Gentoo Penguins&quot;) + scale_colour_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = c(0.9,0.2)) # play with the values to get it where you want it Do you see how straightforwrd it is to adapt the code that produces one plot to get the code you need for another, similar plot? 2.10 Add yet more informtion to the plot Let us include the information of which island the penguins come from by making the shape of the plotted points be dependent on that: penguins |&gt; ggplot(aes(x=flipper_length_mm,y=bill_length_mm,colour=species,shape=island)) + geom_point() + #geom_smooth(method=&quot;lm&quot;, linewidth=0.5,se=FALSE) + # try leaving out the se argument labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Bill length (mm)&quot;, colour= &quot;Species&quot;, shape=&quot;Island&quot;, title=&quot;Penguin size, Palmer Station LTER&quot;, subtitle=&quot;Flipper length and bill length for Adelie, Chinstrap, and Gentoo Penguins&quot;) + scale_colour_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = &quot;right&quot;) # play with the position to get it where you want it. Try &quot;top&quot; etc. 2.11 Distribution of penguin flipper lengths The distribution of a data set is often a useful thing to know. Around which value are the data grouped, how widely spread are they and are the values symmetrically or asymmetrically distributed around the central value? A number of plot types can show this for us. Here we illustrate histograms, density plots, box plots, violin plots and ridge plots. 2.11.1 Histogram First, let’s do a basic histogram. For this we use geom_histogram(). In the ggplot line, in the aes() argument, we need only specify the variable that maps to x, since the software will count how many observations lie within specific narrow ranges of the variable, called bins. Those bin counts will be the y variable of the histogram. To find the distribution of flipper length, we use flipper_length_mmm as the x variable. So we could try penguins |&gt; ggplot(aes(x=flipper_length_mm)) + # why is y not specified? geom_histogram() But this isn’t useful. The histograms for the three species overlap each other, so we need to give each one a different colour, and we need to reduce the opacity of the bars so that the histograms behind are not obscured by the ones in front, where they overlap. Further, we need to stop ggplot from stacking the different histogram bars on top of each other where those for different species are in the same bin. Annoyingly, that is what it does by default, which makes seeing the individual distributions clearly much more difficult. Another thing with histograms, something that can make them a fiddle to use, is that their usefulness in revealing a distrivution is affect by how wide the bins are. By default, ggplot chooses the bin width such that you get 30 bins altogether. This may not be optimal. Here, let’s try specifying the bin width to 4 mm (but see what happens when you try other values, especially very large and very small values). This we can achieve by: incuding fill = species in the aes() argument of ggplot. sepcifying position = identity as an argument of geom_histogram(), to stop the stacking. specifying the opacity argument alpha to be a value less than 1. Here we try alpha = 0.4` - but try other values in the range 0 (transparent) - 1 (opaque), to reduce the opacity. specifying binwidth = 4 - try other values penguins |&gt; ggplot(aes(x=flipper_length_mm, fill = species)) + # why is y not specified? geom_histogram(position = &quot;identity&quot;, alpha = 0.4, binwidth = 4) So, a lot going on, but still only three lines of code! Now add good axis labels, an overall theme, and choose a colour scheme you like, and the legend position, just as you have done before: penguins |&gt; ggplot(aes(x=flipper_length_mm,fill=species)) + geom_histogram(position=&quot;identity&quot;,alpha = 0.4, binwidth = 4) + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Count&quot;, fill= &quot;Species&quot;, # specifies the legend title. See what happens if you omit this line. title=&quot;Penguin flipper lengths&quot;) + # we wouldn&#39;t use this for a figure going in a report. scale_fill_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = c(0.9,0.8)) # play with the position to get it where you want it In the scatter plot and the histogram, we have used colour to distinguish the different species. We can do this because our data set is tidy: there is just one column that species the species, and the same for every other variable. That same feature of the data enables to use another way to represent the different species: facet_wrap(~species). This gives us three separate plots, side by side or one above the other. See it used here: penguins |&gt; ggplot(aes(x=flipper_length_mm,fill=species)) + geom_histogram(position=&quot;identity&quot;,alpha = 0.4, binwidth = 4) + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Count&quot;, fill= &quot;Species&quot;, title=&quot;Penguin flipper lengths&quot;) + facet_wrap(~species) + #try adding the argument ncol = 1. scale_fill_brewer(palette=&quot;Set2&quot;) + # try other palettes, eg &quot;Set1&quot;. theme_bw() + theme(legend.position=&quot;none&quot;) # we don&#39;t need a legend! Just a thought, but do the colours here serve any useful purpose? What extra information do they convey? If you ever think that a feature of a graph conveys no additional information, consider omitting it. Here is the figue before without colours, but going for white brs with grey outlines: penguins |&gt; ggplot(aes(x=flipper_length_mm)) + geom_histogram(position=&quot;identity&quot;,alpha = 0.4, binwidth = 4, fill=&quot;white&quot;,colour=&quot;grey50&quot;) + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Count&quot;, fill= &quot;Species&quot;, # specifies the legend title. See what happens if you omit this line. title=&quot;Penguin flipper lengths&quot;) + # we wouldn&#39;t use this for a figure going in a report. facet_wrap(~species) + #try adding the argument ncol = 1. theme_bw() + theme(legend.position=&quot;none&quot;) # we don&#39;t need a legend! Arguably, this is a better plot than the previous one because it excludes the potentially confusing redundancy of using different colours each species, when we already know which species is the subject of each plot. If you don’t like white as the fill colour, try another one, for exampe this one that I found on Cynthia Brewer’s very useful map colour site: https://colorbrewer2.org penguins |&gt; ggplot(aes(x=flipper_length_mm)) + geom_histogram(position=&quot;identity&quot;,alpha = 0.4, binwidth = 4, fill=&quot;#a6bddb&quot;,colour=&quot;grey50&quot;) + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Count&quot;, fill= &quot;Species&quot;, # specifies the legend title. See what happens if you omit this line. title=&quot;Penguin flipper lengths&quot;) + # we wouldn&#39;t use this for a figure going in a report. facet_grid(island~species) + #try adding the argument ncol = 1. theme_bw() + theme(legend.position=&quot;none&quot;) # we don&#39;t need a legend! Different fill colours would be useful if the different penguin species had distinctive dominant colours, but that isn’t the case! 2.11.2 Density plot An alternative to a histogram, the density plot, gives us a smoothed version of the histogram. The vertical axis on these is not a count, but a measure of the concentration of the data. Here is one with overlapping density plots penguins |&gt; ggplot(aes(x=flipper_length_mm,fill=species)) + geom_density(alpha=0.2) + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Density&quot;, fill= &quot;Species&quot;, title=&quot;Penguin flipper lengths&quot;) + scale_fill_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = &quot;right&quot;) # play with the position to get it where you want it We can also adapt this and do what was done for the histograms and do a set of three, one for each species, using facet_wrap(): penguins |&gt; ggplot(aes(x=flipper_length_mm)) + geom_density(alpha = 0.2, fill=&quot;#a6bddb&quot;,colour=&quot;grey50&quot;) + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Count&quot;, fill= &quot;Species&quot;, # specifies the legend title. See what happens if you omit this line. title=&quot;Penguin flipper lengths&quot;) + # we wouldn&#39;t use this for a figure going in a report. facet_wrap(~species) + #try adding the argument ncol = 1. theme_bw() + theme(legend.position=&quot;none&quot;) # we don&#39;t need a legend! Which is more useful in this case: the overlapping plots on one chart, or the separate charts done using facet_wrap()? Whatever you think here, the answer in other cases will sometimes be one, sometimes the other. Now you have the tools to enable you to try both and make the best choice. 2.11.3 Box plots Box plots are a really useful way to summarize the distribution of numerical response data such as flipper_length_mm across different categorical variables, such as species. We use geom_boxplot() to produce them. Let’s do a basic box plot of flipper lengths for each penguin species: penguins |&gt; ggplot(aes(x=species,y=flipper_length_mm,fill=species)) + geom_boxplot() Now let’s use what we have done before to add code lines that include suitable axis labels and a title give the same ‘theme’ ie overall look as the previous graphs fill the boxes with the same colour for each species. remove the legend that you now have, because you don’t need it (Why?). Use theme(legend.position=\"none\") to do this. penguins |&gt; ggplot(aes(x=species,y=flipper_length_mm,fill=species)) + geom_boxplot() + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;, title=&quot;Penguin flipper lengths&quot;) + scale_fill_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) # no legend needed 2.11.4 Violin Plot using geom_violin() This is a variant on the box plot. Each ‘violin’ is a sideways density plot of the distribution of the data for each species, with its own mirror image to make it look a bit like a violin. The code for these is exactly as for box plots except we use geom_violin(). penguins |&gt; ggplot(aes(x=species,y=flipper_length_mm,fill=species)) + geom_violin() Now we write code to improve this, just as you did the box plot. The final code is the same as for that apart from one line! penguins |&gt; ggplot(aes(x=species,y=flipper_length_mm,fill=species)) + geom_violin() + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;, title=&quot;Penguin flipper lengths&quot;) + scale_fill_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) # no legend needed 2.11.5 Ridge plot This is a variant on the density plot, that is most useful when you have lots of categorical variables. We have only three here, the three penguin species, but let’s try it anyway. For this, we need the ggridges package. This is one of many packages that extend the power of ggplot, and so work in much the same way: # library #install.packages(&quot;ggridges&quot;) # use this once, if you have to, then comment it out. library(ggridges) # basic example penguins |&gt; ggplot(aes(x = flipper_length_mm, y = species, fill = species)) + geom_density_ridges() + labs(x = &quot;Flipper length (mm)&quot;, y = &quot;Species&quot;, title=&quot;Penguin flipper lengths&quot;) + theme_ridges() + theme(legend.position = &quot;none&quot;) Now try producing graphs like the ones above, but for body mass rather than flipper length. 2.12 Bar chart with error bar There are different ways to produce this commonly used way to summarise data. For example we might use one to compare the mean flipper lengths of the different penguin species. For a bar chart of these to be of any use at all, it needs to include error bars that show standard errors of the means, or standard deviations or confidence intervals (Why?). Which you use depends on the story you are trying to tell, but we won’t go into that here. Here, we will add error bars that are ± one standard deviation of the samples I usually first create a summary of the data, in which we calculate the means and appropriate error for each species for whichever variable I am interested in, then feed this summary table to ggplot and use geom_col() to plot the bars, with geom_errorbar() on top of that to plot the error bars. Let’s do that first: flipper_summary &lt;- penguins |&gt; drop_na() |&gt; # these two lines produce a summary table group_by(species) |&gt; summarise(fl.mean = mean(flipper_length_mm), fl.sd = sd(flipper_length_mm)) flipper_summary ## # A tibble: 3 × 3 ## species fl.mean fl.sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 190. 6.52 ## 2 Chinstrap 196. 7.13 ## 3 Gentoo 217. 6.59 To calculate error bar lengths we use a formula \\(\\text{SE} = \\frac{\\text{SD}}{\\sqrt{n}}\\) where \\(n\\) is the number of observations, SD is the standard deviation of the sample and SE is the standard error of the means of the sample. We can use the summary functions sd() to calculate the standard deviation, and n() to calculate \\(n\\). flipper_summary |&gt; ggplot(aes(x = species, y = fl.mean)) + geom_col() + geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd),width=0.1) + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) + theme_bw() Now let’s alter this code so that each bar has a different fill colour, and remove the legend that then appears, since it is unnecessary? flipper_summary |&gt; # we add an argument to colour each bar according to species ggplot(aes(x = species, y = fl.mean, fill = species)) + geom_col() + geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd),width=0.1) + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) + theme_bw() + # include an arument to remove the legend theme() Now let us replace this colour scheme with nicer ones (not just nice, but also colour-blind friendly, perhaps) offered by the Brewer palettes. To do this we can add the line scale_fill_brewer(palette = \"Set2\"). Note: we use scale_colour_brewer() to alter the colours of points, like we did above, or the outline colour of bars, and use scale_fill_brewer() to alter the fill colour of bars. This is what we want to do here. flipper_summary |&gt; ggplot(aes(x = species, y = fl.mean, fill = species)) + geom_col() + geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd),width=0.1) + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) + scale_fill_brewer(palette=&quot;Set2&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) If you don’t like the colours of the palette “Set2” you can try another one. To find out what palettes are available, remember, you can type ?scale_fill_brewer() into the console pane then look at the help that appears in the Help pane (bottom right), and scroll down to the Palettes section. If you agree that having different fill colours for the bars is actually confusing and brings no information to the plot that we do not already know, you can modify the previous plot in the manner that you did for the separate histograms: flipper_summary |&gt; ggplot(aes(x = species, y = fl.mean)) + # add arguments here that give fill colour &quot;#a6bddb&quot; and outline colour &quot;grey50&quot;. geom_col(fill = &quot;#a6bddb&quot;,colour = &quot;grey50&quot;) + geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd),width=0.1) + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) "],["correlation.html", "Chapter 3 Correlation 3.1 The correlation coefficient 3.2 Different values of r. 3.3 Using R to find the correlation coefficient. 3.4 The correlation coefficient measures the degree of linear association. 3.5 Association is not causation 3.6 Examples 3.7 Exercises", " Chapter 3 Correlation This guide to correlation is heavily based on the very helpful chapter in Statistics, by David Freedman, Robert Pisani, Roger Purves and Ani Adhikari, 2nd ed., Norton. The notable statistician Karl Pearson (1857 - 1936) carried out a study to investigate the resemblance between children and their parents. As part of the study, Pearson measured the heights of 1078 parents and of their children at maturity. The heights of the children are plotted against the heights of the parents in the plots below, where we distinguish between father-son and mother-daughter pairs. The taller a father, the taller his sons tend to be. It is the same with mothers and daughters. There is a positive association between a father’s height and the height of his sons. But there is a lot variation - the association is weak. If you know the height of a father, how much does that tell you about the height of his sons? Consider fathers who are about about 67 inches tall, and look at the wide variation in the heights of their sons - - all the points between the two vertical dotted lines. The same is true for the daughters of mother who are about 63 inches tall. If there is a strong association between two variables, then knowing one helps a lot in predicting the other. But when there is a weak association, information about one variable does not help much in guessing the other. When there is no association, it does not help at all. 3.1 The correlation coefficient Suppose we are looking at the relationship between two variables and have already plotted the scatter plot. The graph looks like a cloud of points. How can we summarise it numerically? The first thing we can do is to mark a point that shows the average of the x-values and the average of the y-values. This is the point of averages. It marks the centre of the cloud. The next step is to measure the width of the cloud from side to side, in both the x and the y directions. This can be done using the standard deviations (SD) of the x and y values. Remember that if both x and y are normally distributed, then 95% of the data will lie within about 2 (1.96 if we want to be pernickety) standard deviations of the mean, in each direction. So far, our summary statistics are: mean of the x values, SD of the x values. mean of the y values, SD of the y values. These statistics tell us where the centre of the cloud is and how far spread out it is both vertically and horizontally, but they do not tell the whole story. Consider the following two sets of data plotted below. Both have the same centre and the same spread. However the points in the first cloud are tightly clustered around a line - there is a strong linear association between the two variables. In the second cloud, the clustering is much looser. The strength of the association is different in the two diagrams. To measure the association, one more summary statistic is needed - the correlation coefficient. This coefficient is usually abbreviated as r, for no good reason. The correlation coefficient is a measure of linear association or clustering around a line. The relationship between two variables can be summarized by: the average of the x-values, the SD of the x-values. the average of the y-values, the SD of the y-values. the correlation coefficient r 3.2 Different values of r. Let us see how this looks graphically. In the Figure below we show six scatter plots for hypothetical data. In all six pictures the average is 3 and the standard deviation is 1 for both x and y. The correlation coefficient is printed in each case. The one top left shows a correlation of 0 and the cloud is completely formless. As x increases, y shows no tendency to increase or decrease. It just straggles around. The next diagram has r = 0.4 and a linear pattern is just starting to emerge. The next has r = 0.6 with a stronger linear pattern, and so on. The closer r is to 1 the stronger is the linear association and the more tightly clustered are the points around a line. A correlation of 1, which does not appear in the Figure is often referred to as a perfect correlation. It means that all the points lie exactly on a line so there is a perfect linear correlation between the two variables. Correlation coefficients are always between -1 and 1. The correlation between the heights of identical twins is around 0.95. A scatter diagram for the heights of twins would thus look like the bottom right diagram in the Figure. We see that even with a coefficient this big there is a still a fair degree of scatter. The heights of identical twins are far from being equal all the time. Real data in the life sciences never shows perfect correlation and rarely does it even show strong correlation. It is more common for it to look like Pearson’s father-son data, with weak associations and r values in the range 0.3 to 0.7. This is even more true for data from the social sciences which concern human behaviour. We can also have negative associations between variables. For example women with more education tend to have fewer children. Animals with higher body weight tend to have lower metabolic rates. As one variable increases, the other decreases. When there is negative association, the correlation coefficient has a negative sign. Below we show six examples of negative correlation. As in the previous figure, all the data sets have a mean of 3 and a standard deviation of 1. Correlations are always between -1 and 1, but can take any value in between. A positive correlation means that the cloud slopes up: as one variable increases, so does the other. A negative correlation means that the cloud slopes down. As one variable increases, the other decreases. 3.3 Using R to find the correlation coefficient. First, let us try to find the correlation between two sets of data where we know what the correlation coefficient is, because we created the data ourselves. We will take the x and y data used above for which the correlation coefficient was fixed to be 0.8 cor.test(x,y,method=&quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = 9.3429, df = 48, p-value = 2.234e-12 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6760523 0.8839577 ## sample estimates: ## cor ## 0.8032469 There are different ways to calculate the correlation coefficient. Which of them is appropriate depends mainly on the type of data, and if they are numeric, whether they are normally distributed. If they are, then we use the Pearson method. If they are not, for example because they are ordinal data, then we use the Spearman’s Rank method and write method=“spearman” instead. In this case we can relax the requirement that there is a linear association between the data sets, but there does still need to be a monotonic relationship. It is important to be able to interpret and report the output. First, understand that R is carrying out a test, the null hypothesis of which is that there is no correlation between the values of x and the values of y among the populations from which the x and y data were drawn, so that the correlation coefficient between x and y within those populations is zero. It then reports a p-value: how likely it is that you would have got the data you got for this sample of data if that null hypothesis were true. As with most tests, to do this it uses the data to calculate a so-called test-statistic. How it does this need not concern us here. The details will differ from test to test, and the name given will differ. Here it is called t. It also reports the number of independent pieces of information used to calculate that statistic. This is called the degrees of freedom, here denoted df. This usually (but not necessarily) has a value that is 1,2 or 3 less than the number of data points. Then it reports the p-value. A tiny (close to zero) value here means that it thinks it very unlikely that the samples would be as they are if the x and y variables were not correlated in the populations from which the samples were drawn. A high (by which we usually mean greater than 0.05) value means that there is a reasonable chance that the actual non-zero correlation coefficient could have been found between x and y in the samples, even though those values were not correlated in the wider populations from which the samples were drawn. In that case we would have found no evidence that the x and y data within the population were correlated. This doesn’t mean that they aren’t, just that we have insufficient evidence to reject the null hypothesis that they are not. The p-value reported here is 4.3e-12. That is R’s way of saying what in standard form would be written 4.3 x 10-12. This is a really tiny value. It is 0.0000000000043, which is a very inconvenient way to write such a small number. Hence R’s way of doing it or the standard form way of doing it. In the context of a statistical test and when p is is that small we don’t care about its exact value, we simply note that it is very, very small. We thus can confidently reject the null hypothesis and assert that the data provide evidence that x and y are correlated, in this case positively. Further, it reports the actual correlation coefficient. Here it finds r=0.797, which we happen to know to be correct because we created this data set ourselves, and a 95% confidence interval for the coefficient. The precise meaning of the confidence interval is subtle, but it is a kind of error bar for the correlation coefficient r. It means that if we drew sample after sample from the population and calculated the confidence interval for r for each sample, then 95% of the time that interval would capture the true value of r. If the p-value is small enough that we reject the null-hypothesis, then this confidence interval should not encompass zero. If the p-value is large enough that we do not reject the null hypothesis then this confidence interval will encompass zero. Here, the confidence interval is from 0.67 to 0.88. This does not encompass zero. In fact it is far from zero, so is consistent with our finding a really small p-value. To report the result of this test we would say something like: We find evidence for a strong positive correlation between x and y (Pearson r =0.80, t=9.1, df=48, p&lt;0.001) Note that when the p-value is much less than 0.05 as it is here we do not normally report its exact value, but simply write p&lt;0.01, or p&lt;0.001, and so on. The point is that these ways of reporting it tell the reader that p is way less than 0.05. This is all they need to know to see that we can confidently reject the null hypothesis. 3.3.1 Correlations for real data Let us look at the Iris data set that is built into R. It contains values for the Sepal Width, Sepal Length, Petal Width and Petal Length for samples of 50 plants from each of three species of Iris, setosa, versicolor and virginica. Here are the first few rows: ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa We will look to see if the data allow us to reject the idea that petal width and petal length are not correlated within the wider populations of each of these species: First, let’s plot the data iris |&gt; ggplot(aes(x=Petal.Width,y=Petal.Length,colour=Species)) + geom_point() + labs(x=&quot;Petal Width (mm)&quot;, y=&quot;Petal Length (mm)&quot;) + facet_wrap(~Species,nrow=1,scales=&quot;free&quot;) + theme_classic() + theme(legend.position=&quot;none&quot;) + theme(strip.background=element_blank()) Having seen the plots, do you think that petal width and length are correlated in these samples, and roughly what value for r do you expect in each case? Looking at each graph, it appears that there is a positive correlation for each species, but that this is weaker for setosa and virginica than it is for versicolor. Knowing the petal width for that species gives you a much better idea of the petal length, and vice-versa, than is true for the other two species. Let us find out: iris |&gt; group_by(Species) |&gt; summarise(r=cor.test(Petal.Width,Petal.Length)$estimate, lower.boundb=cor.test(Petal.Width,Petal.Length)$conf.int[1], upper.bound=cor.test(Petal.Width,Petal.Length)$conf.int[2], &quot;p value&quot;=cor.test(Petal.Width,Petal.Length)$p.value) |&gt; kbl(digits=3) |&gt; kable_styling(full_width=0.7) Species r lower.boundb upper.bound p value setosa 0.332 0.059 0.558 0.019 versicolor 0.787 0.651 0.874 0.000 virginica 0.322 0.048 0.551 0.023 The table gives the estimated value for the Pearson correlation coefficient in each case, the lower and upper bound of the confidence interval for that coefficient and the p-value. Do these output provide evidence for a correlation between petal length and petal width in each case? 3.4 The correlation coefficient measures the degree of linear association. Sometimes the Pearson correlation coefficient r is a poor measure of the degree of association within a data set. Outliers and non-linearity are two problem cases. Consider first a data set where there is a very strong association between variables, but where the data sset contains an outlier, and then a data set where there is a strong but non-linear association between variables. Here we mean by ‘strong’ that knowing the value of one variable gives you a very good idea of the value of the other. The outlier in the left-hand figure above brings the correlation coefficient down to 0.08, which is close to zero. The correlation coefficient in the right-hand figure is similarly small at 0.102, despite that there is a strong association between the x and y data. The reason is that the association is non linear. 3.4.1 When is it appropriate to calculate a correlation coefficient? So, we note that the correlation coefficient is a measure of linear association, not of association in general. At least, this is true if you are calculating the Pearson correlation coefficient. If your data are not suitable for that and you decide to calculate the Spearman’s Rank correlation coefficient, then the condition is relaxed somewhat: there might be but there no longer needs to be a linear relationship between the two variables, but there must be a monotonic one. That means that, as one variable increases, the other should either increase or remain constant, or decrease or remain constant - that is, there should be no peaks or troughs in the data. 3.5 Association is not causation A very important and often-repeated point to note is that correlation measures association. But association is not the same as causation. See Spurious Correlations for some amusing examples. 3.6 Examples 3.6.1 Lichen abundance Jovan, S. (2008). Lichen Bioindication of Biodiversity, Air Quality, and Climate: Baseline Results From Monitoring in Washington, Oregon, and California. http://gis.nacse.org/lichenair/doc/Jovan2008.pdf There is a strong negative correlation (r=-0.78) between air quality score and proportion of nitrophyte lichen. This suggests that this proportion can be used as a bioindicator of air quality. 3.6.2 Soil bacteria Lauber, C. L., Hamady, M., Knight, R., &amp; Fierer, N. (2009). Pyrosequencing-based assessment of soil pH as a predictor of soil bacterial community structure at the continental scale. Applied and Environmental Microbiology, 75(15), 5111–5120. https://doi.org/10.1128/AEM.00335-09 In the Figure above, note that the r-values for C and E are close to zero, and the p-values are greater than 0.1, meaning that at this significance level there is no evidence from these data that there is any linear association between soil pH and the relative abundances of Alphaproteobacteria or Beta/Gammaproteobacteria. From the plots, it looks in C as if there no assocation at all, whereas in E it looks as though there might be, but if so then not a linear association, for which the correlation coefficient r would be a poor measure. 3.7 Exercises 3.7.1 Exercise 1 Plots A to F above show scatter plots of different data sets Y against X. Which of them show linear behaviour? Which of them show monotonic behaviour? For which of them might it be appropriate to calculate the following correlation coefficients between X and Y? Pearson r Spearman rank rsp 3.7.2 Exercise 2 Open a new R notebook In the usual way, include to start with code chunks to Load the packages needed tidyverse and here. Read the data set iris.csv (which should be in your data folder already) into an object called iris You can do this with this code chunk: ```{r} filepath&lt;-here(&quot;data&quot;,&quot;iris.csv&quot;) iris&lt;-read_csv(filepath) glimpse(iris) ``` Create a faceted plot of sepal length against sepal width for each species. Calculate the Pearson correlation coefficient between sepal length and sepal width for each species, and display this, plus the lower and upper bounds of the confidence interval and the p-value for each species in a table. For (4) and (5) you can adapt code used on the previous tab. Now: Does it appear that the sepal length and sepal width are correlated for each species? Is the correlation positive or negative? For which species is the correlation strongest? Do the correlation coefficients make sense, given the plots? "],["t-test-for-difference.html", "Chapter 4 t-test for difference 4.1 Preliminaries 4.2 Motivation and example 4.3 The two-sample t-test 4.4 The workflow 4.5 Step One: Summarise the data 4.6 Step Two: Plot the data 4.7 Step Three: Carry out statistical analysis 4.8 The complete script", " Chapter 4 t-test for difference 4.1 Preliminaries In this exercise we find out how to use R to run a two-sample t-test, to determine whether there is evidence to reject the hypothesis that two samples are drawn from the same population. The exercise is based on Chapter 5: Beckerman, Childs and Petchey: Getting Started with R. You should have a 4.2 Motivation and example In our example we will consider concentrations of airborne ozone (O3) at ground level, as measured in gardens around a city. This is of interest because ozone levels can affect how well crops grow, and can impact on human health. We have measurements of airborne ozone levels in ppb taken at two samples of locations in the city: some randomly selected from among gardens in the eastern residential sector and some randomly selected from among gardens in the western sector, close to a zone of heavy industry. Our question is: Is there evidence for a difference between airborne ozone concentrations in the east and the west of the city? From which our null hypothesis is: There is no difference between airborne ozone concentrations in the east and the west of the city. and our alternate, two-sided hypothesis is: There is a difference between airborne ozone concentrations in the east and the west of the city. 4.3 The two-sample t-test This can be used when we have two independent sets of numerical data, and our question is whether the data provide evidence that the sets are drawn from different populations. 4.3.1 Pros of the t-test It can be used when the data set is small. It can still be used when the data set is large. So…if in doubt, just use the t-test, (Kind of, the data do need to fulfil some criteria, but being few in number is fine. See below). 4.3.2 Cons of the t-test It assumes that the data are drawn from a normally distributed population. There are various ways to test if this is true, and you should try at least one of them, but with small samples, just where the t-test is most useful, it can be difficult to tell. In the end we can also appeal to reason: is there good reason to suppose that the data would or would not be normally distributed? When comparing the means of two samples both samples should normally have the same variance, which is a measure of the spread of the data. You need to check that this is the case, or at least have reason to suppose that it should be. (Note: in an actual t-test, it is possible to ignore this requirement - see below). When we have more than two samples and we use the t-test to look for a difference between any two of them, it becomes increasingly likely, the more pairs of samples we compare, that we will decide that we have found a difference because we got a p-value that was less than some pre-determined threshold (which could be anything, but is most often chosen to be 0.05) even if in reality there is none. This is the problem of high false positive rates arising from multiple pairwise testing and is where ANOVA comes in. t-tests are only used to detect evidence for a difference between two groups, not more. ANOVAs (or their non-parametric equivalent) are used when we are looking for differences between more than two groups. 4.4 The workflow 4.4.1 Open your project Open your RStuff (or whatever you have called it) project using File/Open Project, navigating to the project folder, then clicking on the ... .Rproj file you will find there. If your Rstuff folder is not already a Project, then make it one using File/New Project/Existing Directory - then navigate to your Rstuff folder. 4.4.2 Create a new script Create a nw notebook script using File/New File/R Notebook Delete everything from below the yaml section at the top. This is the bit between the pair of lines with three dashes. In the yaml, amend the title and add lines author: \"&lt;your name&gt;\" and date: \"&lt;the date&gt;\". Inside the quotes, add your name and the date. Now add code chunks to carry out the steps listed below. In between the chunks, add as much explanatory text as you want so that next time you come back, you understand what each code chunk is doing. You can format this text using the simple markdown rules to be found in Help/markdown Quick Reference 4.4.3 Load packages We typically include a chunk at or near the top of a script that loads any packages we are going to use. If we load all of them in this one chunk it is easy to see at a glance which ones have been loaded. library(tidyverse) library(here) library(ggfortify) library(cowplot) library(mbhR) library(rstatix) # if that last line doesn&#39;t work, uncomment the next line by deleting the # and run it to install the mbhR package. # remotes::install_github(“mbh038/mbhR”) 4.4.4 Read in and inspect the data # there should be an &#39;ozone.csv&#39; file in your data folder # if not, you should be able to get it from the data folder on Teams or Moodle filepath&lt;-here(&quot;data&quot;,&quot;ozone.csv&quot;) ozone&lt;-read_csv(filepath) #glimpse(ozone) What kind of data have we got? You might also wish to inspect the data using summary(). If so, include a code chunk to do this. 4.5 Step One: Summarise the data With numerical data spread across more than one level of a categorical variable, we often want summary information such as mean values and standard erros of the mean for each level. We can do this by using the group_by() and then summarise() combination. This first group the data however you want to, then calculates whatever summary you have requested for each group. Here we will calculate the number of replicates, the mean and the standard error of the mean for both levels of garden.location ie east and west, then store the result in a data frame calle ozone.summary ozone.summary&lt;-ozone %&gt;% group_by(garden.location) %&gt;% summarise(n = n(), mean.ozone = mean(ozone), se.ozone = sd(ozone)/sqrt(n())) ozone.summary ## # A tibble: 2 × 4 ## garden.location n mean.ozone se.ozone ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 East 10 77.3 2.49 ## 2 West 10 61.3 2.87 From these data, does it look as though there is evidence for a difference between ozone levels in the East and the West? Clearly, the ten gardens in the east had a higher mean ozone concentration than the ten in the west. But is this a fluke? How precisely do we think these sample means reflect the truth about the east and the west of the city? That is what the standard error column tells us. You can think of the standard error as being an estimate of how far from the true ozone concentrations for the whole of the east and the whole of the west our sample means, drawn from just ten locations in each part of the city, are likely to be. Bottom line: the difference between the sample means is about six times the size of the standard errors of each. It really does look as thought east of the city has a higher ozone concentration than the west. 4.6 Step Two: Plot the data Remember, before we do any statistical analysis, it is almost always a good idea to plot the data in some way. We can often get a very good idea as to the answer to our research question just from the plots we do. Here, we will use ggplot() to plot a histogram of ozone levels use the facet_wrap() function to give two copies of the histogram, one for east and one for west, and to stack the histograms one above the other. make the histogram bins 10 ppm wide. ozone %&gt;% ggplot(aes(x=ozone)) + geom_histogram(binwidth=10,fill=&quot;darkred&quot;)+ facet_wrap(~garden.location,ncol=1) + theme_cowplot() Instead of histograms, we could have drawn box plots: ozone %&gt;% ggplot(aes(x=garden.location,y=ozone))+ geom_boxplot()+ labs(x=&quot;Garden Location&quot;, y=&quot;Ozone concentration (ppb)&quot;) + theme_cowplot() or as a dot plot with standard errors of the mean included: # for this chart we will use the summary table that we created above. ozone.summary %&gt;% ggplot(aes(x=garden.location,y=mean.ozone))+ geom_point(size=3) + geom_errorbar(aes(ymin=mean.ozone-se.ozone,ymax=mean.ozone+se.ozone),width=0.1)+ ylim(0,100) + # try leaving this line out. What happens? Which is better? labs(x=&quot;Garden Location&quot;, y=&quot;Ozone concentration (ppb)&quot;, caption=&quot;The data points show mean values, the error bars show plus or minus one standard error of the mean &quot;) + theme_cowplot() Do the data look as though they support the null hypothesis or not? In addition, do the data look as though each group is drawn from a normally distributed population? One of the types of graphs gives you no indication of that while the other two do. Which is the odd one out? Even when looking at the other two figures, when there are so few data it’s kind of hard to tell, no? Let’s now do some stats. 4.7 Step Three: Carry out statistical analysis 4.7.1 Are the data normally distributed? We can go about establishing this in three ways: using an analytical test of normality, using a graphical method and by thinking about what kind of data we have. Let’s consider these in turn. 4.7.2 Normality test - analytical method There are several analytical tests one can run on a set of data to determine if it is normally distributed. One is the Shapiro-Wilk test. For more information on the Shapiro-Wilk test, type ?shapiro.test into the console window. For kicks, try it out on the examples that appear in the help window (which is the bottom right pane, Help tab). One example is testing a sample of data that explicitly is drawn from a normal distribution, the other tests a sample of data that definitely is not. What p-value do you get in each case? How closely do the histograms of each sample resemble a normal distribution? #first we create a data frame containing the two example data sets example1&lt;-rnorm(100, mean = 5, sd = 3) # first example from the help pane example2&lt;-runif(100, min = 2, max = 4) # second example from the help pane df&lt;-tibble(data=c(example1,example2), distribution=c(rep(&quot;normal&quot;,100),rep(&quot;not at all normal&quot;,100))) # then we plot a histogram of each data set ggplot(df,aes(x=data)) + geom_histogram(bins=10,fill=&quot;cornflowerblue&quot;) + facet_wrap(~distribution) + theme_cowplot() # and finally we run a Shapiro-Wilk normality test on each data set shapiro.test(example1) # 100 samples drawn from a normally distributed population ## ## Shapiro-Wilk normality test ## ## data: example1 ## W = 0.99326, p-value = 0.9033 shapiro.test(example2) # 100 samples drawn from a uniformly (ie NOT normally) distributed population ## ## Shapiro-Wilk normality test ## ## data: example2 ## W = 0.94047, p-value = 0.000206 For the examples above, we see that Shapiro-Wilk test gave a hig p-value for the data that we knew were drawn from a normal distribution, an a very low p-value for the data that we knew were not. The Shapiro-Wilk test tests your data against the null hypothesis that it is drawn from a normally distributed population. It gives a p-value. If the p-value is less than 0.05 then we reject the null hypothesis and cannot suppose our data is normally distributed. In that case we would have to ditch the t-test for a difference, and choose another difference test in its place that could cope with data that was not normally distributed. Why don’t we do that in the first place, I hear you ask? Why bother with this finicky t-test that requires that we go through the faff of testing the data for normality before we can use it? The answer is that it is more powerful than other, so-called non-parametric tests that can cope with non-normal data. It is more likely than they are to spot a difference if there really is a difference. So if we can use it, that is what we would rather do. So, onwards, let’s do the Shapiro-Wilk test on our data We want to test each garden group for normality, so we group the data by location as before and and then summarise, this time asking for the p-value returned by the Shapiro-Wilk test of normality. ozone %&gt;% group_by(garden.location) %&gt;% summarise(&#39;Shapiro-Wilk p-value&#39;=shapiro.test(ozone)$p.value) ## # A tibble: 2 × 2 ## garden.location `Shapiro-Wilk p-value` ## &lt;chr&gt; &lt;dbl&gt; ## 1 East 0.0953 ## 2 West 0.599 For both groups the p-value is more than 0.05, so at the 5% significance level we cannot reject the null hypothesis that the data are normally distributed, so we can go on and use the t-test. Yay! 4.7.3 Graphical methods - the quantile-quantile or QQ plot. Confession: I don’t normally bother with numerical tests for normality such as Shapiro-Wilk. I usually use a graphical method instead. For an overview of how normally distributed and non-normally distributed data looks when plotted in histograms, box plots and quantile-quntile plots, see this review We have already seen two ways of plotting the data that might help suggest whether it is plausible that the data are drawn from normally distributed populations. Histograms and box plots both indicate how data is distributed, and for normally distributed data both would be symmetrical. Well, they would be, more or less, if the data set was large enough but for small data sets it can be quite hard to tell from either type of plot whether the data are drawn from a normally distributed population. A better type of plot for making this judgement call is the quantile-quantile or ‘QQ’ plot which basically compares the distribution of your data to that of a normal distribution. If your data are approximately normally distributed then a qq plot will give a straight(-ish) line. Even with small data sets, this is usually easy to spot. ozone %&gt;% ggplot(aes(sample=ozone)) + stat_qq(colour=&quot;blue&quot;) + stat_qq_line() + facet_wrap(~garden.location) + theme_cowplot() Nothing outrageously non-linear there, so that also suggests we can safely use the t-test. 4.7.4 The ‘thinking about the data’ normality test As you might have guessed, this isn’t a test as such, but a suggestion that you think about what kind of data you have: is it likely to be normally distributed within its subgroups or not? If the data are numerical values of some physical quantity that is the result of many independent processes, and if the data are not bounded on either side (say by 0 and 100 as for exam scores) then it is quite likely that that they are. If they are count data, or ordinal data, then it is quite likely that they are not. This way of thinking may be all you can do when data sets are very small and any of the more robust tests for normality presented here leave you not much the wiser. 4.7.5 Now for the actual two-sample t-test So, it looks as though it is plausible that the data are drawn from normal distributions. That means we can go on to use a parametric test such as a t-test and have confidence in its output. We can use the t.test() function for this. This needs to be given a formula and a data set as arguments. Look up t.test() in R’s help documentation, and see if you can get the t-test to tell you whether there is a significant difference between ozone levels in the east and in the west of the city. t.test(ozone~garden.location,data=ozone) ## ## Welch Two Sample t-test ## ## data: ozone by garden.location ## t = 4.2363, df = 17.656, p-value = 0.0005159 ## alternative hypothesis: true difference in means between group East and group West is not equal to 0 ## 95 percent confidence interval: ## 8.094171 24.065829 ## sample estimates: ## mean in group East mean in group West ## 77.34 61.26 ozone %&gt;% t_test(ozone~garden.location) ## # A tibble: 1 × 8 ## .y. group1 group2 n1 n2 statistic df p ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ozone East West 10 10 4.24 17.7 0.000516 Note the ~ tilda symbol. This means ‘is a function of’. So this line means: do a t-test to see if there is a significant difference between the ozone levels in the two garden locations. 4.7.6 Interpret the output of the t-test. Study the output of the t-test. What kind of test was carried out? What data was used for the test? What is the test statistic of the data? How many degrees of freedom were there? Does the number make sense? In a t-test the ’degrees of freedom is one less than the number of data points. What is the p-value? What does the p value mean? What is the confidence interval for the difference between ozone levels in east and west? Does it encompass zero? Is there sufficient evidence to reject the null hypothesis? What does the word ‘Welch’ tell you - look it up in the help for t.test(). 4.8 The complete script Here is a minimal script you could use to run a t-test on the ozone data: Capy this and save it as a .R file # my name # the date # Brief description of what the script is for # load the packages we need library(tidyverse) library(here) library(cowplot) # load the data ozone&lt;-read_csv(here(&quot;data&quot;,&quot;ozone.csv&quot;)) glimpse(ozone) # plot histograms for each location ggplot(ozone,(aes(x=ozone)))+ geom_histogram(binwidth=10,fill=&quot;darkred&quot;)+ facet_wrap(~garden.location,ncol=1) + theme_bw() # what are the means and standard deviations of ozone levels for each location? ozone %&gt;% group_by(garden.location) %&gt;% summarise(avg = mean(ozone),st_dev=sd(ozone)) # are the ozone levels in each location normally distributed? ozone %&gt;% group_by(garden.location) %&gt;% summarise(sw=shapiro.test(ozone)$p.value) # graphical check for normality: # quantile-quantile plots for ozone levels in each location ozone %&gt;% ggplot(aes(sample=ozone)) + stat_qq(colour=&quot;blue&quot;) + stat_qq_line() + facet_wrap(~garden.location) + theme_bw() # and finally, the actual _t_-test t.test(ozone~garden.location,data=ozone) "],["paired-tests-for-difference.html", "Chapter 5 Paired tests for difference 5.1 Which test: paired t-test or Wilcoxon signed rank test? 5.2 Example 5.3 The non-parametric alternative: The Wilcoxon signed rank test 5.4 Relation to one-sample paired test", " Chapter 5 Paired tests for difference Often one has a sample of replicated data where each element has a counterpart in another matched sample - paired data. A common scenario for this is when there are data for the same individual at two different points in time, for example before and after some event such as the application of a treatment. In order to determine whether there is a difference between the two sets, one should take the paired aspect into account and not simply match the whole before-set against the whole after-set without doing this. That would be to throw away the information whereby there is likely to be a greater degree of correlation between the responses of an individual before and after the event than there is between any randomly chosen pairs of individuals before and after the event. 5.1 Which test: paired t-test or Wilcoxon signed rank test? There is a choice between at least two tests: the parametric paired t-test and the non-parametric Wilcoxon signed rank test. Ideally one would use the t-test since it is more powerful than the Wilcoxon test. This means several things, but in particular it means that, all else being equal, it can detect a small difference with higher probability than the Wilcoxon test can. 5.1.1 The paired t-test Where the data are numerical (ie not ordinal) and where the before and after data are both normally distributed around their respective mean values one would use the paired t-test in this scenario. One can test for normality using either a test such as the Shapiro-Wilk test, or graphically using either a histogram, a box plot, or (best), a quantile-quantile plot. 5.1.2 The Wilcoxon Signed Rank test The t-test, an example of a so-called parametric test, is actually pretty robust against departures from normality, but where one doubts its validity due to extreme non-normality or for other reasons such as the ordinal nature of the data, the Wilcoxon signed rank test is a useful non-parametric alternative. It is called non-parametric because it does not make any assumption about the distribution of the data values. It only uses their ranks, where the smallest value gets rank 1, the next smallest gets rank 2, and so on. So, you typically use this test when you would like to use the paired t-test, but you cannot because one or both of the data sets is way off being normally distributed or is ordinal. 5.1.3 Null Hypotheses In both the t-test and the Wilcoxon signed rank tests, the null hypothesis is the usual ‘nothing going on’, ‘there is no difference’ scenario, but there is a subtle difference between them that reflects the different information that they use. In the Wilcoxon signed rank test the null is that the difference between the medians of pairs of observations is zero. This is different from the null hypothesis of the paired t–test, which is that the difference between the means of pairs is zero. 5.1.4 Test output Both tests will give a p value. This is the probability that the mean (t-test) or median (Wilcoxon signed rank) paired differences between the corresponding before and after sample elements would be equal to or greater than it actually is for the data if the null hypothesis were true. If the p value is less than some pre-decided ‘significance level’, usually taken to be 0.05, then we reject the null hypothesis. If it is not, then we fail to reject the null hypothesis. 5.2 Example We will use as an example a data set from Laureysens et al. (2004) that has measurements of metal content in the wood of 13 poplar clones growing in a polluted area, once in August and once in November. The idea was to investigate the extent to which poplars could absorb metals from the soil and thus be useful in cleaning that up. Under a null hypothesis, there would be no difference between the metal concentrations in the plant tissue between August and November. Under an alternate hypothesis, there would be. Laureysens, I. et al. (2004) ‘Clonal variation in heavy metal accumulation and biomass production in a poplar coppice culture: I. Seasonal variation in leaf, wood and bark concentrations’, Environmental Pollution, 131(3), pp. 485–494. Available at: https://doi.org/10.1016/j.envpol.2004.02.009. Concentrations of aluminum (in micrograms of Al per gram of wood) are shown below. 5.2.1 Load packages library (tidyverse) library(here) library(cowplot) # to make the plots look nice library(gt) # for making nice tables 5.2.2 Load data filepath &lt;- here(&quot;data&quot;,&quot;poplars-paired_np.csv&quot;) poplars &lt;- read_csv(filepath,show_col_types = FALSE) # table of the data poplars |&gt; gt() #mzsliqtgen table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mzsliqtgen thead, #mzsliqtgen tbody, #mzsliqtgen tfoot, #mzsliqtgen tr, #mzsliqtgen td, #mzsliqtgen th { border-style: none; } #mzsliqtgen p { margin: 0; padding: 0; } #mzsliqtgen .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mzsliqtgen .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mzsliqtgen .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mzsliqtgen .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mzsliqtgen .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mzsliqtgen .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mzsliqtgen .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mzsliqtgen .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mzsliqtgen .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mzsliqtgen .gt_column_spanner_outer:first-child { padding-left: 0; } #mzsliqtgen .gt_column_spanner_outer:last-child { padding-right: 0; } #mzsliqtgen .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mzsliqtgen .gt_spanner_row { border-bottom-style: hidden; } #mzsliqtgen .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mzsliqtgen .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mzsliqtgen .gt_from_md > :first-child { margin-top: 0; } #mzsliqtgen .gt_from_md > :last-child { margin-bottom: 0; } #mzsliqtgen .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mzsliqtgen .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mzsliqtgen .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mzsliqtgen .gt_row_group_first td { border-top-width: 2px; } #mzsliqtgen .gt_row_group_first th { border-top-width: 2px; } #mzsliqtgen .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mzsliqtgen .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mzsliqtgen .gt_first_summary_row.thick { border-top-width: 2px; } #mzsliqtgen .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mzsliqtgen .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mzsliqtgen .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mzsliqtgen .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mzsliqtgen .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mzsliqtgen .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mzsliqtgen .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mzsliqtgen .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mzsliqtgen .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mzsliqtgen .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mzsliqtgen .gt_left { text-align: left; } #mzsliqtgen .gt_center { text-align: center; } #mzsliqtgen .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mzsliqtgen .gt_font_normal { font-weight: normal; } #mzsliqtgen .gt_font_bold { font-weight: bold; } #mzsliqtgen .gt_font_italic { font-style: italic; } #mzsliqtgen .gt_super { font-size: 65%; } #mzsliqtgen .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mzsliqtgen .gt_asterisk { font-size: 100%; vertical-align: 0; } #mzsliqtgen .gt_indent_1 { text-indent: 5px; } #mzsliqtgen .gt_indent_2 { text-indent: 10px; } #mzsliqtgen .gt_indent_3 { text-indent: 15px; } #mzsliqtgen .gt_indent_4 { text-indent: 20px; } #mzsliqtgen .gt_indent_5 { text-indent: 25px; } ID Clone August November 1 Balsam_Spire 8.1 11.2 2 Beaupre 10.0 16.3 3 Hazendans 16.5 15.3 4 Hoogvorst 13.6 15.6 5 Raspalje 9.5 10.5 6 Unal 8.3 15.5 7 Columbia_River 18.3 12.7 8 Fritzi_Pauley 13.3 11.1 9 Trichobel 7.9 19.9 10 Gaver 8.1 20.4 11 Gibecq 8.9 14.2 12 Primo 12.6 12.7 13 Wolterson 13.4 36.8 5.2.3 Plot the data Before we do any test on some data to find evidence for a difference or a trend, it is a good idea to plot the data. This will reveal whatever patterns there are in the data and how likely they are to reveal a truth about the population from which they have been drawn. 5.2.4 Tidy the data In this case there is work to do before we can plot the data. The problem is that the data is ‘untidy’. The two levels of the factor month are spread across two columns, August and November. For plotting purposes it will be useful to ‘tidy’ the data so that there is only one column containing both levels of month and another containing the aluminium concentrations. The function pivot_longer() can do this for us: poplars_tidy &lt;- poplars |&gt; pivot_longer (August:November,names_to=&quot;month&quot;,values_to=&quot;Al_conc&quot;) head(poplars_tidy,8) |&gt; gt() #eagbrmueva table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #eagbrmueva thead, #eagbrmueva tbody, #eagbrmueva tfoot, #eagbrmueva tr, #eagbrmueva td, #eagbrmueva th { border-style: none; } #eagbrmueva p { margin: 0; padding: 0; } #eagbrmueva .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #eagbrmueva .gt_caption { padding-top: 4px; padding-bottom: 4px; } #eagbrmueva .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #eagbrmueva .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #eagbrmueva .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #eagbrmueva .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #eagbrmueva .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #eagbrmueva .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #eagbrmueva .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #eagbrmueva .gt_column_spanner_outer:first-child { padding-left: 0; } #eagbrmueva .gt_column_spanner_outer:last-child { padding-right: 0; } #eagbrmueva .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #eagbrmueva .gt_spanner_row { border-bottom-style: hidden; } #eagbrmueva .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #eagbrmueva .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #eagbrmueva .gt_from_md > :first-child { margin-top: 0; } #eagbrmueva .gt_from_md > :last-child { margin-bottom: 0; } #eagbrmueva .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #eagbrmueva .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #eagbrmueva .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #eagbrmueva .gt_row_group_first td { border-top-width: 2px; } #eagbrmueva .gt_row_group_first th { border-top-width: 2px; } #eagbrmueva .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #eagbrmueva .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #eagbrmueva .gt_first_summary_row.thick { border-top-width: 2px; } #eagbrmueva .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #eagbrmueva .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #eagbrmueva .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #eagbrmueva .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #eagbrmueva .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #eagbrmueva .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #eagbrmueva .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #eagbrmueva .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #eagbrmueva .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #eagbrmueva .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #eagbrmueva .gt_left { text-align: left; } #eagbrmueva .gt_center { text-align: center; } #eagbrmueva .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #eagbrmueva .gt_font_normal { font-weight: normal; } #eagbrmueva .gt_font_bold { font-weight: bold; } #eagbrmueva .gt_font_italic { font-style: italic; } #eagbrmueva .gt_super { font-size: 65%; } #eagbrmueva .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #eagbrmueva .gt_asterisk { font-size: 100%; vertical-align: 0; } #eagbrmueva .gt_indent_1 { text-indent: 5px; } #eagbrmueva .gt_indent_2 { text-indent: 10px; } #eagbrmueva .gt_indent_3 { text-indent: 15px; } #eagbrmueva .gt_indent_4 { text-indent: 20px; } #eagbrmueva .gt_indent_5 { text-indent: 25px; } ID Clone month Al_conc 1 Balsam_Spire August 8.1 1 Balsam_Spire November 11.2 2 Beaupre August 10.0 2 Beaupre November 16.3 3 Hazendans August 16.5 3 Hazendans November 15.3 4 Hoogvorst August 13.6 4 Hoogvorst November 15.6 Now we can plot the data as a box plot, with one box for August and one for November ie one for each level of the factor month. Had we not first tidied the data, we could not have done this. poplars_tidy |&gt; # group = ID makes the lines join elements of each pair ggplot(aes(x = month, y = Al_conc, fill = month, colour = month)) + # alpa (= opacity) &lt; 1 in case any points are on top of each other geom_boxplot(outlier.size=0,alpha=0.5) + geom_point(alpha = 0.5) + geom_line(aes(group=ID),colour = &quot;grey60&quot;) + labs(x = &quot;Month&quot;, y = &quot;Al conc.(mu g Al / g wood)&quot;) + theme_cowplot() + theme(legend.position = &quot;none&quot;) Does it look as though the difference between the medians could plausibly be zero for the population? Or, put another way, if it was zero, how big a fluke would this sample be? That is what the p value actually tells us. 5.2.5 Check for normality of differences Before we use the t-test, we need to check that it is OK to do so. The null hypothesis of the Shapiro-Wilk test is that the data set given to it is drawn from a normally distributed population. shapiro.test(poplars$August-poplars$November) ## ## Shapiro-Wilk normality test ## ## data: poplars$August - poplars$November ## W = 0.92667, p-value = 0.3081 The p value is very high. Thus we can reasonably assume that the differences between the August and November aluminium concentrations in the sample could plausibly have been drawn from a normally distributed population, despite the outlier value in the November sample. Thus we can reasonably test for difference using a paired t-test. We can do this in R using the function t.test(), where we give to the function both the August and the November data, knowing that each August value has a counterpart November value, and we set the argument paired to TRUE. t.test(poplars$August, poplars$November, paired = TRUE) ## ## Paired t-test ## ## data: poplars$August and poplars$November ## t = -2.3089, df = 12, p-value = 0.03956 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -9.5239348 -0.2760652 ## sample estimates: ## mean difference ## -4.9 All parts of the output have meaning and are useful, but here we will focus on just two: the p value is equal to 0.040. Hence, if we have chosen the usual significance value of 0.05, we can take this to mean that there is evidence of a significant difference between the August and November values. the lower and upper bounds of the 95% confidence interval are (-9.52, -0.28). This tells us that if samples such as we have were collected again and again, then the mean difference between the August and the November paired values would be in this range 95% of the time. The key thing is that this range does not encompass zero. This means that we can be confident at the 95% level that there is a non-zero change on going from August to November, and, in particular, that the August value is lower than the November value. 5.3 The non-parametric alternative: The Wilcoxon signed rank test To be safe, because of that outlier, let us test for difference using the Wilcoxon signed rank test. In R this is done using the function wilcox.test(), with the argument paired set to TRUE. wilcox.test(poplars$August, poplars$November, paired = TRUE) ## ## Wilcoxon signed rank exact test ## ## data: poplars$August and poplars$November ## V = 16, p-value = 0.03979 ## alternative hypothesis: true location shift is not equal to 0 We see that the conclusion (in this case) is the same. 5.4 Relation to one-sample paired test The two-sample paired tests as we have done above are the same as doing a one-sample test to see if the differences between the August and November paired values is different from zero. This is true whether we do a t-test or a Wilcoxon signed rank test. t.test(poplars$August - poplars$November, mu = 0, data = poplars) ## ## One Sample t-test ## ## data: poplars$August - poplars$November ## t = -2.3089, df = 12, p-value = 0.03956 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -9.5239348 -0.2760652 ## sample estimates: ## mean of x ## -4.9 wilcox.test(poplars$August - poplars$November, mu = 0, data = poplars) ## ## Wilcoxon signed rank exact test ## ## data: poplars$August - poplars$November ## V = 16, p-value = 0.03979 ## alternative hypothesis: true location is not equal to 0 "],["anova-factorial-experiments-and-model-simplification.html", "Chapter 6 ANOVA: Factorial experiments and model simplification’ 6.1 Factorial experiments and model simplification 6.2 Files needed 6.3 Open your Project 6.4 Load packages 6.5 Read in the data 6.6 Make R recognise the categorical variables as factors, and order the levels. 6.7 Summarise the data 6.8 Plot the data 6.9 ANOVA 6.10 Model Simplification 6.11 Reporting the results", " Chapter 6 ANOVA: Factorial experiments and model simplification’ This exercise sheet is heavily indebted to Michael Crawley’s Statistics: An introduction using R, 2nd Ed, Wiley. Published in 2015 this emphasises statistics over R (in fact, much of the R he presents is written prior to the advent of the tidyverse dialect which we use here, and so may seem terse if that is what you are used to). It is very useful and is at a higher level than Beckerman, Childs and Petchey’s Getting Started in R: An introduction for biologists, 2nd Ed. OUP published in 2017. Their book also includes a simpler version of the example explored here. 6.1 Factorial experiments and model simplification The best model is the one that adequately explains the data with fewest parameters. This means with the smallest possible number of degrees of freedom. If we have a very large number of parameters, a model can fit any data set but be of limited use in generalising beyond it (we will have overfitted the data). If we have too few we will not explain much of the variance of the data. A balance must be struck. Hence we want the minimal adequate model. As Einstein almost said, a model should be as simple as possible, but no simpler. A factorial experiment has two or more factors, each with two or more levels, plus replication for each combination of factor levels. This means that we can investigate whether statistical interactions occur in which the effect of one factor depends on the value of another factor. We take an example from a farm-trial of animal diets. There are two factors: diet and supplement. diet is a factor with three levels: barley, oats and wheat, where barley is the diet that has always been used and the other two are potential alternatives. The purpose of the trial is to see if their use makes a difference to growth outcomes. supplement is a factor with four levels: control, agrimore, supergain and supersupp, where control could mean the absence of any supplement or the supplement used up to now, whose effects we are hoping to improve upon through use of one of the others included in the trial. The response variable gain is weight gain after 6 weeks. There were 48 individual cows in total with 4 for each combination of diet and supplement. Having the same number of replcates for each combination of levels means that this is a balanced design. 6.2 Files needed To be put in the Project/scripts folder: ANOVA_two_way_with_model_simplification.html (this worksheet) ANOVA_two_way_template.Rmd (the script where you fill in the code chunks) To be put in Project/data folder growth.csv In the following, we present the code you need to analyse this data together with explanatory text. Read the text closely so that you understand what each chunk of code is intended to do. In the accompanying template file, fill in the code as you go in the empty chunks, using this worksheet as a guide. As you complete each line of code, run it using Ctrl-Enter or Cmd-Enter on a Mac. Alternatively, wait until you have completed the code for a chunk then run the whole chunk in one go by pressing the little green arrow at the top right of the chunk. Whichever way you choose, you are encouraged to view the code presented here as one way to do the analysis. Feel free to hack away at it and change things, to try different approaches and see what happens. That way you will learn. You may also wish to add your own text between the chunks. 6.3 Open your Project You should be working within a folder that you have designated as what RStudio calls a ‘Project’. If you are, the name of your Project will appear at the top right of the RStudio window. Inside your Project folder you should have a scripts folder for scripts like the one you are working from, and a data folder for all the data files. You will also see, at the top level of the Project, the .RProj file. You can see all this in the Files pane, bottom-right. 6.4 Load packages I normally load all the packages in the chunk below into every script. The most important is the tidyverse package which is a goody bag containing several other packages. Loading this saves you from having to load each of those individually. The most often used among these is readr for reading and writing data from/to files, dplyr for data manipulation, and ggplot2 for plotting. Others will be used from time to time, and we don’t really need to be aware of that when it happens or to worry about it, so long as tidyverse has been loaded. library(tidyverse) # for data manipulation and plotting, and much else besides library(here) # for finding our data easily library(cowplot) # gives a nice theme for plots library(ggfortify) # for diagnostic plots 6.5 Read in the data The growth.csv data file needs to be in the data folder within the Project folder. In this chunk we read the growth.csv data into an R object to which we give the name weights. filepath&lt;-here(&quot;data&quot;,&quot;growth.csv&quot;) weights&lt;-read_csv(filepath) # this function is from the readr package, part of tidyverse glimpse(weights) ## Rows: 48 ## Columns: 3 ## $ supplement &lt;chr&gt; &quot;supergain&quot;, &quot;supergain&quot;, &quot;supergain&quot;, &quot;supergain&quot;, &quot;contro… ## $ diet &lt;chr&gt; &quot;wheat&quot;, &quot;wheat&quot;, &quot;wheat&quot;, &quot;wheat&quot;, &quot;wheat&quot;, &quot;wheat&quot;, &quot;whea… ## $ gain &lt;dbl&gt; 17.37125, 16.81489, 18.08184, 15.78175, 17.70656, 18.22717,… You see from the output of the glimpse() function that weights has three columns and 48 rows. Two columns are of data type &lt;chr&gt; which is R-speak for text, and the other is data type &lt;dbl&gt; which is R-speak for numerical data with a decimal point. 6.6 Make R recognise the categorical variables as factors, and order the levels. At the moment, the contents within the variables supplement and diet are not being recognised as levels of factors. R is just thinking of them as text (or &lt;chr&gt; in R-speak), as we can see from the output of the glimpse() function in the chunk above. Let us fix that, as it will be useful for them to be recognized for what they are so that we can order the levels in a way that makes sense for our context, our plots and our analysis. Sometimes levels of a factor have a natural order, such as Low, Mid and High as the levels of the factor Tidal Zone and sometimes they do not, for example Apples, Oranges and Pears as levels of the factor Fruit. Here, in the case of both our factors, we only wish to impose order among the levels in so far as we would like what we regard as the control or reference level to be first. By default, R puts the levels of a factor in alphabetical order. This is the order in which the boxes of a box plot would be displayed, reading left to right. In an ANOVA setting it means that differences of outcome (in this case, weight gain of the cows) are later calculated for each combination of levels with respect to the outcome for the combination of levels that are alphabetically first, in this case barley for diet and agrimore for supplement. In both the box-plot and the ANOVA output case this default ordering is not necessarily what we want. Normally, we want what we regard as the control levels to be the reference level and in this case that means barley for diet and control for supplement. To ensure that a variable is regarded as a factor, and then to get its levels in the order we would like, we use the factor() function. In the following chunk, factor() is used to designate both the supplement and diet columns of the data set as factors, and the level order of each is specified, with control coming first for supplement and barley coming first for diet. weights &lt;- weights |&gt; mutate(supplement = factor(supplement, levels = c(&quot;control&quot;,&quot;agrimore&quot;, &quot;supergain&quot;, &quot;supersupp&quot;)), diet = factor(diet, levels = c(&quot;barley&quot;,&quot;oats&quot;, &quot;wheat&quot;))) glimpse(weights) ## Rows: 48 ## Columns: 3 ## $ supplement &lt;fct&gt; supergain, supergain, supergain, supergain, control, contro… ## $ diet &lt;fct&gt; wheat, wheat, wheat, wheat, wheat, wheat, wheat, wheat, whe… ## $ gain &lt;dbl&gt; 17.37125, 16.81489, 18.08184, 15.78175, 17.70656, 18.22717,… Do you see how the variable types of the supplement and diet columns have been changed to &lt;fct&gt;? It worked! To get control to be the reference level of supplement we needed to force the issue in this way. If we hadn’t then agrimore would have been regarded as such, since it is alphabetically the first among the levels of supplement. We didn’t need to do this for diet, since the stipulated ordering of the levels is just the alphabetical order and so we would have had that by default anyway. Sometimes, though, it doesn’t hurt to throw in a little redundancy for the sake of clarity. So, now we have control as the reference level for supplement and barley as the reference level for diet. Now we can see more easily in our analysis what difference is made to weight gain when we change diet or supplement or both from a ‘business as usual’ combination of a barleydiet and the control supplement. 6.7 Summarise the data Our question is a difference question: is there evidence from the data that using this or that diet in combination with this or that supplement makes a difference to growth? For an answer to this we will end up doing a 2-way ANOVA including the possibility of an interaction, then, as we will see, a simpler ANOVA that ignores the possibility of the interaction. All well and good, but before we go to those lengths, we do something more basic: we calculate the mean and standard error of the mean for each of the twelve combinations of diet and supplement. There isn’t a function in base R with which we can calculate standard error of the mean directly, but we can do so knowing the standard deviation of the sample \\(\\text{SD}\\) (using sd()) and the sample size \\(n\\) (using n()) using this formula: \\[ \\text{SE}=\\frac{SD}{\\sqrt{n}}\\] # we use the group_by() and summarise() functions from dplyr (the package within tidyverse for data manipulation) growth_summary&lt;-weights |&gt; group_by(diet,supplement) |&gt; summarise(mean_gain = mean(gain),se_gain = sd(gain)/sqrt(n())) |&gt; ungroup() growth_summary diet supplement mean_gain se_gain barley control 23.29665 0.7032491 barley agrimore 26.34848 0.9187479 barley supergain 22.46612 0.7710644 barley supersupp 25.57530 1.0599015 oats control 20.49366 0.5056319 oats agrimore 23.29838 0.6131592 oats supergain 19.66300 0.3489388 oats supersupp 21.86023 0.4132292 wheat control 17.40552 0.4604420 wheat agrimore 19.63907 0.7099260 wheat supergain 17.01243 0.4852821 wheat supersupp 19.66834 0.4746443 Note the ordering of the diet and supplement levels in their respective columns: just what we have imposed! 6.8 Plot the data The next step, as so often before we launch into actual statistics, is to plot the data in a way that sheds light on the question we have. Here, we can use the use the means and standard errors of the mean that we have just calculated to produce a useful kind of line plot that in this context is often referred to as an interaction plot: growth_summary |&gt; ggplot(aes(x=supplement,y=mean_gain, colour = diet, group = diet)) + geom_point(size=2) + geom_line() + geom_errorbar(aes(ymin = mean_gain - se_gain, ymax = mean_gain + se_gain), width=0.1) + labs(x=&quot;Supplement&quot;, y=&quot;Mean weight gain&quot;) + scale_fill_brewer() + theme_cowplot() Note that on this plot the error bars are standard errors of the mean. Any caption to a figure that contains error bars should explain what those error bars mean. In particular, it should say whether they are standard deviations of the sample, standard errors of the mean or confidence intervals. These are all different from each other. A good explanation of the difference is given by [Cummings et al][1]. (2007). This interaction plot is useful in that we see that both diet and supplement have an effect on growth and that the effect of one is altered little by the value of the other, the result of which is that the lines are more or less parallel. This suggests that we have main effects of both diet and supplement, but little or no interaction between them. 6.8.1 Questions What could the line plot look like if: There were no main effect of both diet and supplement, and no interaction There were a main effect of diet, no main effect of supplement and no interaction? There were no main effect of diet, a main effect of supplement and no interaction? There were main effects of both and an interaction between them? The plots tell you a great deal about what main effects and/or interactions there may be. 6.9 ANOVA Now for the actual statistical test. We will conduct a two-way ANOVA, which will look to see if there is evidence that either diet or supplement or both affect growth rate (the so-called main effects), and if the effect of one depends on the nature of the other (the so-called interaction). The null hypothesis is that neither has any main effect and that there is no interaction. Now we can use either of the functions aov() or lm() to fit a factorial ANOVA (the choice affects only whether we get an ANOVA table or a list of parameter estimates as the default output from summary().). Here, we will use lm(). We estimate parameters for the main effects of each level of diet and each level of supplement, plus terms for the interaction between diet and supplement. The interaction degrees of freedom are the product of those for diet and supplement ie (3-1) x (4-1) = 6. The model is: gain ~ diet + supplement + diet:supplement which can be written more simply using the asterisk notation as: gain ~ diet * supplement 6.9.1 Construct the model First we construct the model using lm() and store the outputs of all the maths that `lm() does in an object called model0: model0&lt;-lm(gain ~ diet * supplement, data = weights) 6.9.2 Do we reject the null hypothesis? To get an overall picture, we first use anova() to see if there is evidence to reject the null anova(model0) ## Analysis of Variance Table ## ## Response: gain ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## diet 2 287.171 143.586 83.5201 2.999e-14 *** ## supplement 3 91.881 30.627 17.8150 2.952e-07 *** ## diet:supplement 6 3.406 0.568 0.3302 0.9166 ## Residuals 36 61.890 1.719 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The ANOVA table shows that there a main effect of both diet and supplement (p&lt;0.001 in both cases), but that there is no hint of an interaction between diet and supplement (p = 0.917). Does that tally with what you see in the interaction plot? Clearly therefore, the effects of diet and supplement are merely additive (ie whichever level of one you have it does not affect the impact on growth of whichever level of the other you choose). The ANOVA table does not show us effect sizes or allow us to work out which if any of the levels of the two factors are significantly different. For this, summary() is more useful: summary(model0) ## ## Call: ## lm(formula = gain ~ diet * supplement, data = weights) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.48756 -1.00368 -0.07452 1.03496 2.68069 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 23.2966499 0.6555863 35.536 &lt; 2e-16 *** ## dietoats -2.8029851 0.9271390 -3.023 0.00459 ** ## dietwheat -5.8911317 0.9271390 -6.354 2.34e-07 *** ## supplementagrimore 3.0518277 0.9271390 3.292 0.00224 ** ## supplementsupergain -0.8305263 0.9271390 -0.896 0.37631 ## supplementsupersupp 2.2786527 0.9271390 2.458 0.01893 * ## dietoats:supplementagrimore -0.2471088 1.3111726 -0.188 0.85157 ## dietwheat:supplementagrimore -0.8182729 1.3111726 -0.624 0.53651 ## dietoats:supplementsupergain -0.0001351 1.3111726 0.000 0.99992 ## dietwheat:supplementsupergain 0.4374395 1.3111726 0.334 0.74060 ## dietoats:supplementsupersupp -0.9120830 1.3111726 -0.696 0.49113 ## dietwheat:supplementsupersupp -0.0158299 1.3111726 -0.012 0.99043 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.311 on 36 degrees of freedom ## Multiple R-squared: 0.8607, Adjusted R-squared: 0.8182 ## F-statistic: 20.22 on 11 and 36 DF, p-value: 3.295e-12 This is a complex model as there are 12 estimated parameters: 6 main effects and 6 interactions. Notice that although the ‘controls’ for diet and supplement (barley and control) do not appear to be in the table, they are there really, in the first row. The value 23.30 kg in the first row of the Estimate column on the left, labelled ‘Intercept()’ gives us the actual weight gain outcome for the combination of the two control levels, barley as diet and control as supplement. Check that this value tallies with what is shown in summary tables above, and in the interaction plot. The weight gain values for all the other combinations of the levels of each factor are given as differences from this reference level. So for example in row two, where diet is changed from barley to oats but supplement is still control, the value in the table is -2.8. This means that the weight gain when the diet is changed to oats but the supplement left as the control is 2.80 kg less than the reference value, and so must be 23.30-2.80 = 20.50 kg. This agrees with the value in the summary table of mean values that was calculated above, and tallies with the interaction plot. In row seven we see that the effect of the interaction between the diet oats and the supplement agrimore is - 0.247. This means that on going from the reference levels of barley and control, for which the gain is 23.30, the change in gain is not just the sum of the two main effects (-2.80 for switch of diet to oats and +3.05 for switch of supplement to agrimore, but is modified by their interaction, of size - 0.247. Hence the mean gain for a diet of oats and a supplement of agrimore is the intercept value plus the sum of the two main effects, plus the interaction term: 23.297 - 2.803 + 3.052 - 0.247 = 23.299) See if you can tally the other effect values in the summary table with the mean values given in table above and in the interaction plot for other combinations of diet and supplement. Here is a table to help you interpret the output of the summary() function. term meaning type_of_effect estimate absolute_value p_value significance (Intercept) barley + control Main effect 23.30 23.30 &lt;0.001 *** dietoats oats + control Main effect -2.80 20.49 0.005 ** dietwheat wheat + control Main effect -5.89 17.41 &lt;0.001 *** supplementagrimore barley + agrimore Main effect 3.05 26.35 0.002 ** supplementsupergain barley + supergain Main effect -0.83 22.47 0.376 supplementsupersupp barley + supersupp Main effect 2.28 25.58 0.019 *. dietoats:supplementagrimore oats + agrimore Interaction -0.25 23.05 0.852 dietwheat:supplementagrimore wheat + agrimore Interaction -0.82 22.48 0.537 dietoats:supplementsupergain oats + supergain Interaction 0.00 23.30 1.0 dietwheat:supplementsupergain wheat + supergain Interaction 0.44 23.73 0.741 dietoats:supplementsupersupp oats + supersupp Interaction -0.91 22.38 0.491 dietwheat:supplementsupersupp wheat + supersupp Interaction -0.02 23.28 0.99 The output of the summary() function re-emphasises that none of the interaction terms are significant. It also suggests that a minimum adequate model will contain 5 parameters: an intercept, which just means that there is non-zero growth when the diet and supplement are the reference values, a difference from that growth due to changing the diet to oats, a difference due to changing it towheat, a difference due to changing the supplement to agrimore while keeping barley as the diet, and a difference due to changing the supplement instead to suppersupp.. 6.10 Model Simplification Given the results of the full interaction model, we begin model simplification by leaving out the interaction terms, to leave us with an additive model: model_1&lt;-lm(gain ~ diet + supplement, data = weights) summary(model_1) ## ## Call: ## lm(formula = gain ~ diet + supplement, data = weights) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.30792 -0.85929 -0.07713 0.92052 2.90615 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 23.4263 0.4408 53.141 &lt; 2e-16 *** ## dietoats -3.0928 0.4408 -7.016 1.38e-08 *** ## dietwheat -5.9903 0.4408 -13.589 &lt; 2e-16 *** ## supplementagrimore 2.6967 0.5090 5.298 4.03e-06 *** ## supplementsupergain -0.6848 0.5090 -1.345 0.185772 ## supplementsupersupp 1.9693 0.5090 3.869 0.000375 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.247 on 42 degrees of freedom ## Multiple R-squared: 0.8531, Adjusted R-squared: 0.8356 ## F-statistic: 48.76 on 5 and 42 DF, p-value: &lt; 2.2e-16 6.10.1 Check the validity of the linear model We ought to pause here for a moment and just check that we are OK to go ahead and analyse our data using a general linear model (of which ANOVA is an example, linear regression and t-tests being others). We will use autoplot() from the ggfortify package, which gives us the standard four diagnostic plots. autoplot(model_1) + theme_cowplot() # autoplot() is from the ggfortify package. Well, that all looks fine. In particular, from the top-left figure we see that the variance of the residuals is more or less constant and from the top-right figure, the quantile-quantile plot, we get a pretty good approximation of a straight line which tells us that the residuals are more or less normally distributed. These are two key assumptions that must be at least approximately satisfied by data if it is going to make any sense to use a linear model to analyse it. We won’t discuss here the other two diagnostic plots, but they look fine too. So we are good to go using ANOVA with this data. Back to interpreting the output of the ANOVA: It is clear that we need to retain all three levels of diet since the effect values of each differ from each other by an amount that is several times the standand errors, so that t &gt;&gt; 1. It is not clear that we need all the levels of supplement, however. supersupp is not obviously different from agrimore (difference = -0.727 with standard error = 0.509), yet both are clearly different from control. However supergrain is not obviously different from control (difference = -0.68, error = 0.509). Hence we are tempted to try a new model with just two levels of the factor supplement which we might sensibly call “best”, by which we mean agrimore or supersupp, and “worst” by which we mean control or supergrain. We’ll name this new factor supp2. weights &lt;- weights |&gt; mutate(supp2 = ifelse(supplement %in% c(&quot;agrimore&quot;,&quot;supersupp&quot;),&quot;best&quot;,&quot;worst&quot;)) If we calculate the means and standard errors for weight gain under each diet for each of the two new classifications of supplement, and then plot them, we get this new interaction plot: weights |&gt; group_by(diet,supp2) |&gt; summarise(mean_gain = mean(gain), se_gain = sd(gain)/sqrt(n())) |&gt; ungroup() |&gt; ggplot(aes(x = supp2,y = mean_gain,colour = diet,group=diet)) + geom_point(size=2) + geom_line() + geom_errorbar(aes(ymin = mean_gain-se_gain, ymax = mean_gain+se_gain), width=0.1) + labs(x=&quot;Supplement&quot;, y=&quot;Mean weight gain&quot;) + scale_fill_brewer() + theme_cowplot() From this we can see that diet clearly makes a difference to weight gain, since the three lines are separated by a distance much larger than the standard errors, the best supplement clearly makes a difference since there is a consistent drop on going from ‘best’ to ‘worst’, again by an amount that is much larger than the error bars, and there is clearly no interaction between diet and supplement, since the lines are parallel within the wiggle room allowed by the error bars, which means that the effect of diet does not depend on supplement, and the effect of supplement does not depend on diet. Now we will make the simpler model, calling it model_2 (for comparison with the first additive model, model_1) # additive model whee the supplements have been condensed from four to two: best and worst model_2&lt;-lm(gain ~ diet + supp2, data = weights) and them compare the two additive models: anova(model_1,model_2) ## Analysis of Variance Table ## ## Model 1: gain ~ diet + supplement ## Model 2: gain ~ diet + supp2 ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 42 65.296 ## 2 44 71.284 -2 -5.9876 1.9257 0.1584 When we use anova() in this way it is testing the explanatory power of the second model against that of the first ie how much of the variance in the data does each explain. Its null hypothesis is that both models explain just as much of the variance as the other. The simpler model has saved two degrees of freedom and is not significantly different in explanatory power than the more complex model (p = 0.158). Hence this is a better candidate as a minimal adequate model. All the parameters are significantly different from zero and from each other. summary(model_2) ## ## Call: ## lm(formula = gain ~ diet + supp2, data = weights) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.6716 -0.9432 -0.1918 0.9293 3.2698 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.7593 0.3674 70.106 &lt; 2e-16 *** ## dietoats -3.0928 0.4500 -6.873 1.76e-08 *** ## dietwheat -5.9903 0.4500 -13.311 &lt; 2e-16 *** ## supp2worst -2.6754 0.3674 -7.281 4.43e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.273 on 44 degrees of freedom ## Multiple R-squared: 0.8396, Adjusted R-squared: 0.8286 ## F-statistic: 76.76 on 3 and 44 DF, p-value: &lt; 2.2e-16 In this table, line one (Intercept) tells us that the mean weight gain when on the barley diet and best supplement is 25.76 kg line two dietoats tells us that there is a significant drop in weight gain of 3.1 kg when diet is changed to oats. line three dietwheat tells us that there is a significant drop in weight gain of 5.99 kg when diet is changed to wheat. line four supp2worst tells us that there is a significant drop in wight gain of 2.68 kg when supplement is changed to worst. In all cases, p&lt; 0.001, as indicated not only by the number in the Pr(&gt;|t|) column, but also by the ’***’ in the right-most column of the table. 6.11 Reporting the results We have now reduced our initial 12 parameter model to a four parameter model that is much more tractable and easier to communicate. Our advice would be that for maximum weight gain a diet of barley with a supplement of agrimore or supersupp would be best. If we were reporting this as a statistical test, we might say something like: A diet of barley with a supplement of agrimore or supersupp was to offer significant improvements over alternatives. There was no evidence of any interaction between diet and supplement. (ANOVA 2-way, F3,44 = 76.76, p &lt; 0.001) [1]: Cumming, G., Fidler, F., &amp; Vaux, D. L. (2007). Error bars in experimental biology. Journal of Cell Biology, 177(1), 7–11. https://doi.org/10.1083/jcb.200611141 "],["one-way-anova.html", "Chapter 7 One-way ANOVA 7.1 Load packages 7.2 Remove observations with missing values 7.3 Summary - group by species and sex 7.4 Plot the data 7.5 One-way ANOVA 7.6 Reporting the Result.", " Chapter 7 One-way ANOVA In this exercise we will carry out a method of analysis known as ANOVA - this is what is commonly used when you have one or more categorical variables, such as species, sex and so on, and a numerical response variable such as body mass and you want to know if there is a difference in the response variable between the categories. 7.1 Load packages library(tidyverse) # for data manipulation and plots, and more besides library(ggfortify) # this is useful for diagnostics library(palmerpenguins) # for the palmer penguin data The palmerpenguins package comes with two in-built data sets on penguins. The simplest of them is called penguins and is the one we will use in this exercise: glimpse(penguins) ## Rows: 344 ## Columns: 8 ## $ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … ## $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… ## $ body_mass_g &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … ## $ sex &lt;fct&gt; male, female, female, NA, female, male, female, male… ## $ year &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… 7.2 Remove observations with missing values We can see from the first few values of the glimpse table that some rows have missing values (NAs). We need to decide what to do with them. Here we will simply remove them! Here is a way to remove any row that contains missing values in one column or another: penguins_clean &lt;- penguins |&gt; drop_na() glimpse(penguins_clean) ## Rows: 333 ## Columns: 8 ## $ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6… ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2… ## $ flipper_length_mm &lt;int&gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18… ## $ body_mass_g &lt;int&gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800… ## $ sex &lt;fct&gt; male, female, female, female, male, female, male, fe… ## $ year &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… That has removed 11 rows of data, so we haven’t lost too much information. 7.3 Summary - group by species and sex Here we use the famliar group_by() and summarise() construction to find the mean body mass for each combination of species and sex. We also calculate the standard error of those means and the number of individuals in each group. penguins_clean |&gt; group_by(species, sex) |&gt; summarise(n = n(), mean_bm = mean(body_mass_g), se_bm = sd(body_mass_g)/sqrt(n()) ) |&gt; ungroup() ## # A tibble: 6 × 5 ## species sex n mean_bm se_bm ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie female 73 3369. 31.5 ## 2 Adelie male 73 4043. 40.6 ## 3 Chinstrap female 34 3527. 48.9 ## 4 Chinstrap male 34 3939. 62.1 ## 5 Gentoo female 58 4680. 37.0 ## 6 Gentoo male 61 5485. 40.1 Looking at this table, does it look as though females and males have different weights? If so, which is heavier? Is this true for all species? Do the different species weigh the same? 7.4 Plot the data To get further insight into these questions, we can plot the data. Here we will do a box plot penguins_clean |&gt; ggplot(aes(x=species, y = body_mass_g, fill = sex)) + geom_boxplot() + labs(x = &quot;Species&quot;, y = &quot;Body mass (g)&quot;, fill = &quot;Sex&quot;) + scale_colour_brewer(palette = &quot;Set1&quot;) + theme_bw() + theme(legend.position= c(0.1,0.8)) What do you think now about size differences between species and the two sexes? There is a lot going on here, so let’s approach this more simply to begin with and concentrate solely on the difference between the females of the species. 7.5 One-way ANOVA Let’s ask the question: do the body weights differ between females of the different species? There is just one factor here, species, and it has more than two levels - the three different species - and the reponse variable is numeric, so it is highly likely that the appropriate test to answer this question is a one-way ANOVA. ‘One way’ because there is one factor, and ‘ANOVA’ (instead of t-test) because there are more than two levels. 7.5.1 Null hypothesis Pretty much all of the commonly used statistics tests are asking the question: what is the probability that you would have got this data, or more extreme data, if the null hypothesis were true? Their job is to calculate that probability, which is called a p-value. There is a lot more besides, but what this means is that in carrying out any of these tests we at least need to have a hypothesis in mind and its corresponding null hypothesis. The null, remember, is typically the ‘nothing going on’, there is no effect, no difference scenario. So in this case, a suitable null hypothesis would be that there is no difference in body mass between the females of the different penguin species. To see if there is evidence from the data to reject this null, we will follow a sequence of steps that will be common to many analyses: get the data clean/prepare the data summarise the data plot the data construct the model using whatever test is appropriate, in this case a one-way ANOVA check whether the model is valid inspect the model output reject or fail to reject the null hypothesis if we reject the null, carry out post-hoc tests (maybe) simplify the model and redo the analysis For the penguin data, getting it was easy as it came with the palmerpenguins package. To prepare the data, we start with the full data set and narrow it down to just the females, using the filter() function, and again make sure there are no lines with missing values, using drop_na(). We save this cleaned data set in an object called females. females &lt;- penguins |&gt; filter(sex == &quot;female&quot;) |&gt; drop_na() Then let’s summarise these values to find the number of individuals, the mean body mass for each species, and the standard errors of those means: females |&gt; group_by(species) |&gt; summarise(n = n(), mean.mass_f = mean(body_mass_g), se.mass_f = sd(body_mass_g)/sqrt(n())) ## # A tibble: 3 × 4 ## species n mean.mass_f se.mass_f ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 73 3369. 31.5 ## 2 Chinstrap 34 3527. 48.9 ## 3 Gentoo 58 4680. 37.0 We should inspect this summary table and see what we already think about whether the null hypothesis is likely to be rejected, or not. Now let’s plot them, using a box plot (but choose your favourite plot type): females |&gt; ggplot(aes(x=species, y = body_mass_g)) + geom_boxplot(fill = &quot;#9ebcda&quot;) + # pick your favourise colour from https://colorbrewer2.org/ labs(x = &quot;Species&quot;, y = &quot;Body mass (g)&quot;) + theme_bw() From the summary table and the plot, what do you think? Do the masses differ between the species? 7.5.2 The actual ANOVA You probably have a good idea what the answer is, as to our question, but now we will move on to the actual statistics test, in this case a one-way ANOVA. An ANOVA is one variant of a range of anlysis techniques known as ‘linear models’. If you were to look under the hood, you would see that mathematics behind it is exactly the same as that behind linear regression, which we use when we have a continuous explanatory variable and where we fit straight lines onto a scatter plot. Thus it is no surprise that the ANOVA is carried out in R in exactly the same way as linear regression would be: First, we use the lm() function to construct a linear model of the data: 7.5.3 Construct the model females.model &lt;- lm(body_mass_g ~ species, data = females) Here the lm() function has done all the maths of the ANOVA, and we have saved the results of that in an object called females.model. Note the use of the formula body_mass_g ~ species as the first argument of the lm() function, where this means ‘body mass as a function of species’. 7.5.4 Is the model valid? All linear models are only valid if the data meet a number of criteria. Chief among these for an ANOVA is that the spread of the data should be roughly the same in each subset, and that the data within each subset should be normally distributed around their respective mean values. Only if there conditions are met can be just go on and trust the output of the model. If they are not, we need to transform the data in some way until they are, or use a different test. There are various ways we can find out whether these consitions are met. A useful one is to do it graphically, and a useful way to do that is to use the autoplot() function from the ggfortify package. Let’s do it: autoplot(females.model) + theme_bw() All four graphs presented here tell us something about the validity or not of our model. Here we will just focus on the upper two: top-left: this shows the spread of the residual masses (diference between an individual’s mass and the mean mass for its species) for each species. We see that the spread of these values is aout the same for all three species. Check! top-right: this is a qq-plot, or quantile-quantile plot. This compares the distribution of the residuals for each species with a normal distribution. If the residuals are normally distributed, we will get a straight line. If not, we won’t. To get an idea of what qq-plots can look like for data that definitely are not normally distriuted, see https://rpubs.com/mbh038/725314. Here, there is a hint of a curve, but this is really pretty good for a real data set. No such data is ever perfectly normally distrivuted, so the best we are looking for, in practice is something approximating a straight line, often with some raggedness at either end. So, check again! On both counts, we are good to go: we can reasonably trust the output of the ANOVA. So what is this output? We find this in three steps 7.5.5 The overall picture First, we use the anova() function anova(females.model) ## Analysis of Variance Table ## ## Response: body_mass_g ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## species 2 60350016 30175008 393.25 &lt; 2.2e-16 *** ## Residuals 162 12430757 76733 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This gives us an overvierw of all the data and asks the question: how likely is it that you would have got your data if species made no difference to body mass. There are three things to note: the test statistic, here called an F-value. This is a number calculated from the data. If the validity criteria for the test have been met by the data, then this has a known distribution. The bigger it is, the more likely it is that the null will be rejected. the degrees of freedom, here denoted as Df and listed in the first column. These are the numer of independent pieces of information in the data, which here means, how many species and how many penguins. the p-value, which is the probability of getting an F value as big as or bigger than the one actually found, if the null hypothesis were true. This is is the number listed at the right as Pr(&gt;F). The F value here is huge and the p-value is tiny, so tiny that it is esentially zero. Thus we can confidently reject the null hypothesis and assert that there is evidence from the data that body mass of females differs between at least one pair of species. Which two, or between all of them, and by how much we don’t yet know. This first step just tells us whether there is some difference somewhere. If there were no evidence of any difference we would stop the analysis right here. But there is a differnce in this case, so we continue 7.5.6 The detailed picture We use the summary() function for this: summary(females.model) ## ## Call: ## lm(formula = body_mass_g ~ species, data = females) ## ## Residuals: ## Min 1Q Median 3Q Max ## -827.21 -193.84 20.26 181.16 622.79 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3368.84 32.42 103.908 &lt; 2e-16 *** ## speciesChinstrap 158.37 57.52 2.754 0.00657 ** ## speciesGentoo 1310.91 48.72 26.904 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 277 on 162 degrees of freedom ## Multiple R-squared: 0.8292, Adjusted R-squared: 0.8271 ## F-statistic: 393.2 on 2 and 162 DF, p-value: &lt; 2.2e-16 The is a lot in ths output, so let’s just consider the coefficient table, to begin with. Focus first on the top left value, in the Estimate column. This tells us the mean body mass of the reference or ‘Intercept’ species. In this case that is ‘Adelie’, purely because ‘Adelie’ comes alphabetically before the other two species names, ‘Chinstrap’ and ‘Gentoo’. By default, R will always order levels of a factor alpabetically. This is often a nuisance, and we have to tell R to reorder the levels the way we want them, but here it is OK. So, the mean mass of female Adelie penguins in our sample is 3368 g. Cross ceck that with your initial summary table and the box plot. What about the other two species? Here’s the thing: for all rows except the first in the Estimate column we are not given the absolute value but the difference between their respective mean values and the reference mean in the first, ‘Intercept’ row. Thus, we are being told that Chinstrap females in the sample have a mean body mass that is 158.37 g heavier than that of Adelie females, so that their mean body mass is 3368.84 + 158.37 = 3527.27g. Again, cross chck that with your summary table and the box plot. Is it right? What about Gentoo females? Were they heavier than Adelie penguins, and if so, by how much? What was their mean body mass. Why doesn’t summary() just tell us the actual body masses instead for all three species instead of doing it in this round about way? The reason is that ANOVA is concerned with detecing evidence of difference. This we are being told what the differences are between each of the levels and one reference level, which here is Adelie. Are those differenes signifcant? We use the right hand p-value column for that. Look in the rows for Chinstrap and Gentoo penguins. In both cases the p values are much less than 0.05. This is telling us that in both cases there is evidence that females of these species are significantly heavier than those of the Adelie species. Note that we have only been told, so far, about the magnitude and significance of differences between all the levels and the reference level. We are not told the significance of of any difference between any other pair of levels. So in particular, the ANOVA does not tell us whether there is a significant difference between the masses of Chinstrap and Gentoo females (although we may have a good idea what the answer is, from our initial summary table and plot). To find the answer to that, we o post-hoc tests: 7.5.7 Post hoc tsts. A final step of most ANOVA analyses is to perform so-called post-hoc (‘after the fact’) tests which make pairwise comparisons between all possible pairs of levels, tell us what the differences are between those pairs and whether the differences are significant. Whatever method is used for this, it needs to take account of the danger of making Type-one errors that arises when multiple pair-wise tests are done. A commonly used function for doing this is Tukey’s Honest Signficant Difference: TukeyHSD() TukeyHSD(aov(body_mass_g ~ species, data = females)) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = body_mass_g ~ species, data = females) ## ## $species ## diff lwr upr p adj ## Chinstrap-Adelie 158.3703 22.32078 294.4197 0.0179471 ## Gentoo-Adelie 1310.9058 1195.64908 1426.1624 0.0000000 ## Gentoo-Chinstrap 1152.5355 1011.00620 1294.0648 0.0000000 In each row of the output we see the difference between the mean masses of the females of two species, where a positive value tells us that the first named species has the heavier mass. So, we see that Gentoo females in the sample were on average 1310.9 g heavier than Adelie females. Compare these differences with your initial summary table and your box plot. Do they agree? They should! The right-hand column ‘p adj’ tells us whtehr these difference are significant. If the p values are less than 0.05 then they are, at the 5% significance level. In this case they all are. The p values are so tiny for the differences between Gentoo and the other two species that that they are reported as zero. 7.6 Reporting the Result. We try to use plain English to report our results, while still telling the reader what test was used and the key outputs of the test. Try to report the name of the test, the test statistic, the degrees of freedom, and the p-value. if. the p-value is really small then it is common to report it as p&lt;0.01, or p&lt;0.001. No one cares if it is a billionth or a squillionth. t just matters that is t is really small, if that is the case. If it is onlt just below 0.05, then I would report it isn full, so we might write p = 0.018. If p &gt; 0.05 then conventiallly it is not reported, except to say p &gt; 0.05. In this case, we might say something like: We find evidence that there is a difference between the body masses of females of the penguon species Adelie, Chinstrap and Gentoo (ANOVA, df = 2, 162, F = 393, p &lt; 0.001). In particular Gentoo are more than 1kg heavier than the other two (p&lt; 0.001) while the difference between Chinstrap and Adelie is smaller, at 158g, but still significant (p = 0.018). "],["simple-linear-regression.html", "Chapter 8 Simple linear regression 8.1 Simple Linear Regression 8.2 Load packages 8.3 Get the data 8.4 Plot the data 8.5 Make a simple model using linear regression 8.6 Check assumptions 8.7 Interpretation of the model 8.8 Back to the figure 8.9 Conclusion 8.10 Sample script", " Chapter 8 Simple linear regression A class of analytical models that you will use this year and next go under the name General Linear Models. They include linear regression, multiple regression, ANOVA, ANCOVA, Pearson correlation and t-tests. Despite appearances, these models are all fundamentally linear models. They share a common framework for estimation (least squares) and a common set of criteria that the data must satisfy before they can be used. These criteria centre around the idea of normally distributed residuals. An important stage of any analysis that uses linear models is that these assumptions are checked, as part of the Plot -&gt; Model -&gt; Check Assumptions -&gt; Interpret -&gt; Plot again workflow. Here, we will go through an example of simple linear regression - suitable for trend data where we wish to predict a continuously varying response, given a value of a continuous explanatory variable. As we go we show code snippets from an R script that does this job, and, at the bottom, an example complete script that you could adapt to your own needs. 8.1 Simple Linear Regression As an example, we ask the question: does plant growth rate depend on soil moisture content? We predict that more moisture will probably allow higher growth rates. We note that this means there will be a clear relationship between the variables, one that should be apparent if we plot the response (dependent) variable - plant growth rate - against the explanatory (independent) variable - soil moisture content. We note that both the explanatory variable and the dependent variables are continuous - they do not have categories. What we want to do in linear regression is be able to predict the value of the dependent variable, knowing the value of the independent variable. In practice, this means drawing a ‘best fit’ straight line through the data and determining the intercept and gradient of this line. 8.2 Load packages library(tidyverse) library(here) library(ggfortify) library(cowplot) # un-comment and run the next line if you have not yet installed mbhR. # remotes::install_github(&quot;mbh038/mbhR&quot;) library(mbhR) 8.3 Get the data We have a data set to explore our question: The plants data set is available through the mbhR package which you have already installed and loaded data(plants) glimpse(plants) ## Rows: 50 ## Columns: 2 ## $ soil.moisture.content &lt;dbl&gt; 0.4696876, 0.5413106, 1.6979915, 0.8255799, 0.85… ## $ plant.growth.rate &lt;dbl&gt; 21.31695, 27.03072, 38.98937, 30.19529, 37.06547… We see that the data set contains two continuous variables, as expected. 8.4 Plot the data We can use the package ggplot2, which is part of tidyverse to do this: plants |&gt; ggplot(aes(x=soil.moisture.content, y=plant.growth.rate)) + geom_point() + labs(x=&quot;Soil moisture content&quot;, y=&quot;Plant growth rate (mm/week)&quot;) + xlim(0,2) + ylim(0,50) + theme_cowplot() From the plot, we note that: there is an upward trend that is plausibly linear within this range of soil misture content. The more moisture there is in the soil, the greater the growth rate of the plants appears to be. the variance of the data, that is the range of vertical spread is approximately constant for the whole range of soil moisture content. This is one of the key criteria that data must satisfy if we are to analyse them using a linear model such as simple linear regression. we can estimate the intercept and gradient of a best fit line just by looking at the plot. Roughly speaking, the moisture content varies from 0 to 2, while the growth rate rises from 20 to 50, a rise of about 30. Hence the gradient is about 30/2 = 15 mm/week, while the intercept is somewhere between 15 mm and 20 mm / week. It is always good practice to examine the data before you go on to do any statistical analysis. 8.5 Make a simple model using linear regression We use the function lm() to do this, and we save the results in an object to which we give the name model_pgr. This function needs a formula and some data as its arguments: model_pgr&lt;-lm(plant.growth.rate ~ soil.moisture.content, data = plants) This reads: ‘Fit a linear model, where we hypothesize that plant growth rate is a function of soil moisture content, using the variables from the plants data frame.’ 8.6 Check assumptions Before we rush into interpreting the output of the model, we need to check whether it was valid to use a linear model in the first place. Whatever the test within which we are using a linear model, we should do the necessary diagnostic checks at this stage. You can do this using tests designed for the purpose, but I prefer to do it graphically, using a function autoplot() from the package ggfortify. You give this the model we have just created using lm() and it produces four very useful graphs. I suggest that, after once installing ggfortify you include the line library(ggfortify) at the start of every script. Here is how you use it: autoplot(model_pgr, smooth.colour=NA) + theme_cowplot() The theme_cowplot() part is not necessary, but it gives the plots a nice look, so why not? These plots are all based around the `residuals’, which is the vertical distance between observed values and fitted values ie between each point and the best fit line through the points - the line which the linear model is finding for us, by telling us its intercept and gradient. Note that in simple linear regression, the best fit line is the one that minimises that sum of the squared residuals. So what do these plots mean? Top-left: This tells you about the structure of the model. Was it a good idea to try to fit a straight line to the data? If not, for example because the data did follow a linear trend, then there will be humps or troughs in this plot. Top-right: This evaluates the assumption of normality of the residuals. The dots are the residuals and the dashed line is the expectation under the normality assumption. This is a much better way to check normality than making a histogram of the residuals, especially with small samples. Bottom-left: This examines the assumption of equal variance of the residuals. A linear model assumes that the variance is constant over all predicted values of the response variables. There should be no pattern. Often, however, there is. With count data, for example, the variance typically increases with the mean. Bottom-right: This detects leverage - which means points that have undue influence on the gradient of the fitted line, and outliers. If you have outliers in your data, you need to decide what to do with them. In the case of these data, we are good to go! There is no discernible pattern in either of the left-hand plots, the qq-plot is about as straight as you ever see with real data, and there are no points exerting undue high influence. 8.7 Interpretation of the model Now that we have established that the data meet the criteria required for the model to be valid, we can go ahead and inspect its output. We will do this using two tools that we also use for every other general linear model we implement (t-test, ANOVA etc). These are anova() and summary() Let us first use anova(): anova(model_pgr) ## Analysis of Variance Table ## ## Response: plant.growth.rate ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## soil.moisture.content 1 2521.15 2521.15 156.08 &lt; 2.2e-16 *** ## Residuals 48 775.35 16.15 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The F value here is an example of a ‘test statistic’, a number that a test calculates from the data, from which it is possible to further calulate how likely it is that you would have got the data you got if the null hypothesis were true. This particular test statistic is the ratio of the variation in the data that is explained by the explanatory variable to the leftover variance. The bigger it is, the better the job that the explanatory variable is doing at explaining the variation in the dependent variable. The p value, which here is effectively zero, is the chance you would have got an F value this big or bigger from the data in the sample if in fact there were no relationship between plant growth rate and soil moisture content. If the p value is small (and by that we usually mean less than 0.05) then we can reject the null hypothesis that there is no relationship between plant growth rate and soil moisture content. Hence, in this case, we emphatically reject the null: there is clear evidence that plant growth rate is at least in part explained by soil moisture content. Now we use the summary() function: summary(model_pgr) ## ## Call: ## lm(formula = plant.growth.rate ~ soil.moisture.content, data = plants) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.9089 -3.0747 0.2261 2.6567 8.9406 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 19.348 1.283 15.08 &lt;2e-16 *** ## soil.moisture.content 12.750 1.021 12.49 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.019 on 48 degrees of freedom ## Multiple R-squared: 0.7648, Adjusted R-squared: 0.7599 ## F-statistic: 156.1 on 1 and 48 DF, p-value: &lt; 2.2e-16 This gives us estimates of the intercept (19.348) and gradient (12.750) of the best fit line through the data. The null hypothesis is that both these values are zero, and the p-value is our clue as to whether we can reject this null. Here, in both cases, we clearly can. We also see the Adjusted R-squared value of 0.7599. This is the proportion of the variance in the dependent variable that is explained by the explanatory variable. Thus it can vary between 0 and 1. A large value like this indicates that soil moisture content is a good predictor of plant growth rate. 8.8 Back to the figure Typically, a final step in our analysis involves including the model we have fitted into the original figure, if that is possible in a straightforward way. In the case of simple linear regression, it is. It means adding a straight line with the intercept and gradient displayed by the summary() function. We do this by adding a line geom_smooth(method = \"lm\") to our plot code: plants |&gt; ggplot(aes(x=soil.moisture.content, y=plant.growth.rate)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x=&quot;Soil moisture content&quot;, y=&quot;Plant growth rate (mm/week)&quot;) + xlim(0,2) + ylim(0,50) + theme_cowplot() This gives both a straight line and the ‘standard error’ of that line - meaning, roughly speaking, the wiggle room within which the ‘true’ line , for the population as opposed to this sample drawn from it, probably lies. 8.9 Conclusion We have carried out a simple linear regression on continuous data. This is an example of a general linear model. We first plotted the data, then we used lm() to fit the model. Next we inspected the validity of the model using autoplot. We then inspected the model itself using first anova() then summary(). Finally we included the output of the model on the plot, in this case by adding to it a straight line with the intercept and gradient determined by the regression model. 8.10 Sample script An example script to do linear regression might look like the following, here written as though a .R script. For this to work you will need to work within a project, with the data in a subfolder of that called “data”. Here, the data is taken to be a .csv file called mydata.csv, with two columns of data, one called x_values and the other called y_values. You need to change these to suit your own data. # load packages library(tidyverse) library(here) library(ggfortify) library(cowplot) # load data filepath &lt;- here(&quot;data&quot;, &quot;mydatafile.csv&quot;) mydata &lt;- read_csv(filepath) glimpse(mydata) # plot the data mydata |&gt; ggplot(aes(x=x_values, y=y_values)) + geom_point() + labs(x = &quot;X variable&quot;, y = &quot;Y variable&quot;) + theme_cowplot() # fit the model mydata.model &lt;- lm (y_values ~ x_values, data = mydata) # diagnostics autoplot(mydata.model) # investigate the model anova(mydata.model) summary(mydata.model) # replot the data, now with the model included mydata |&gt; ggplot(aes(x=x_values, y=y_values)) + geom_point() + geom_smooth(method=&quot;linear&quot;) + labs(x = &quot;X variable&quot;, y = &quot;Y variable&quot;) + theme_cowplot() "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
